{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MBTI Faculty Voice Research - Google Colab\n",
    "\n",
    "This notebook contains:\n",
    "1. **MBTI Voice Accuracy Experiment** - Run the full 480-trial experiment\n",
    "2. **Ada Lovelace Essay Generation** - Generate essay on MBTI research\n",
    "3. **Upload to Commonplace** - Upload essay to Inquiry Institute Commonplace\n",
    "\n",
    "## Setup\n",
    "\n",
    "1. Install dependencies\n",
    "2. Set API keys (OpenRouter, Supabase)\n",
    "3. Run the cells below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:02:00.483864Z",
     "iopub.status.busy": "2026-01-14T04:02:00.483674Z",
     "iopub.status.idle": "2026-01-14T04:02:01.282557Z",
     "shell.execute_reply": "2026-01-14T04:02:01.281329Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q openai pydantic python-dotenv requests pandas matplotlib seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure API Keys\n",
    "\n",
    "Set your API keys below. For security, you can use Colab's secrets manager or set them directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:02:01.314231Z",
     "iopub.status.busy": "2026-01-14T04:02:01.313995Z",
     "iopub.status.idle": "2026-01-14T04:02:01.579362Z",
     "shell.execute_reply": "2026-01-14T04:02:01.578470Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  Colab Secrets not available, using manual input...\n",
      "üí° Tip: Set secrets in Colab using the üîë icon in the left sidebar\n",
      "   Secrets to add: OPENROUTER_API_KEY, SUPABASE_URL, SUPABASE_ANON_KEY\n",
      "\n"
     ]
    },
    {
     "ename": "StdinNotImplementedError",
     "evalue": "getpass was called, but this frontend does not support input requests.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m userdata\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müîê Using Colab Secrets Manager...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mStdinNotImplementedError\u001b[39m                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgetpass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m getpass\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# OpenRouter API Key (required for experiment and essay generation)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m OPENROUTER_API_KEY = \u001b[43mgetpass\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEnter OpenRouter API Key (sk-or-v1-...): \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mOPENROUTER_API_KEY\u001b[39m\u001b[33m\"\u001b[39m] = OPENROUTER_API_KEY\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Supabase credentials (required for uploading to Commonplace)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/ipykernel/kernelbase.py:1370\u001b[39m, in \u001b[36mKernel.getpass\u001b[39m\u001b[34m(self, prompt, stream)\u001b[39m\n\u001b[32m   1368\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._allow_stdin:\n\u001b[32m   1369\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mgetpass was called, but this frontend does not support input requests.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1370\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[32m   1371\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1372\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n",
      "\u001b[31mStdinNotImplementedError\u001b[39m: getpass was called, but this frontend does not support input requests."
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Try to use Colab Secrets Manager (preferred method)\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    print(\"üîê Using Colab Secrets Manager...\")\n",
    "    \n",
    "    # Get secrets from Colab Secrets Manager\n",
    "    OPENROUTER_API_KEY = userdata.get('OPENROUTER_API_KEY')\n",
    "    SUPABASE_URL = userdata.get('SUPABASE_URL', 'https://xougqdomkoisrxdnagcj.supabase.co')\n",
    "    SUPABASE_ANON_KEY = userdata.get('SUPABASE_ANON_KEY')\n",
    "    \n",
    "    os.environ[\"OPENROUTER_API_KEY\"] = OPENROUTER_API_KEY\n",
    "    os.environ[\"NEXT_PUBLIC_SUPABASE_URL\"] = SUPABASE_URL\n",
    "    os.environ[\"NEXT_PUBLIC_SUPABASE_ANON_KEY\"] = SUPABASE_ANON_KEY\n",
    "    \n",
    "    print(\"‚úÖ API keys loaded from Colab Secrets!\")\n",
    "    \n",
    "except (ModuleNotFoundError, KeyError) as e:\n",
    "    # Fallback to manual input if not in Colab or secrets not set\n",
    "    print(\"‚ö†Ô∏è  Colab Secrets not available, using manual input...\")\n",
    "    print(\"üí° Tip: Set secrets in Colab using the üîë icon in the left sidebar\")\n",
    "    print(\"   Secrets to add: OPENROUTER_API_KEY, SUPABASE_URL, SUPABASE_ANON_KEY\\n\")\n",
    "    \n",
    "    from getpass import getpass\n",
    "    \n",
    "    # OpenRouter API Key (required for experiment and essay generation)\n",
    "    OPENROUTER_API_KEY = getpass(\"Enter OpenRouter API Key (sk-or-v1-...): \")\n",
    "    os.environ[\"OPENROUTER_API_KEY\"] = OPENROUTER_API_KEY\n",
    "    \n",
    "    # Supabase credentials (required for uploading to Commonplace)\n",
    "    SUPABASE_URL = input(\"Enter Supabase URL (https://xxx.supabase.co): \").strip() or \"https://xougqdomkoisrxdnagcj.supabase.co\"\n",
    "    os.environ[\"NEXT_PUBLIC_SUPABASE_URL\"] = SUPABASE_URL\n",
    "    \n",
    "    SUPABASE_ANON_KEY = getpass(\"Enter Supabase Anon Key: \")\n",
    "    os.environ[\"NEXT_PUBLIC_SUPABASE_ANON_KEY\"] = SUPABASE_ANON_KEY\n",
    "    \n",
    "    print(\"\\n‚úÖ API keys configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run MBTI Voice Accuracy Experiment\n",
    "\n",
    "Run the full experiment or load existing results. The experiment tests 10 faculty personae across 16 MBTI types with 3 test prompts each (480 trials total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:02:01.582203Z",
     "iopub.status.busy": "2026-01-14T04:02:01.581840Z",
     "iopub.status.idle": "2026-01-14T04:02:02.311594Z",
     "shell.execute_reply": "2026-01-14T04:02:02.310659Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Running MBTI Voice Accuracy Experiment...\n",
      "   This will test 10 personae √ó 16 MBTI types √ó 3 prompts = 480 trials\n",
      "   This may take 15-30 minutes depending on API response times.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Downloaded mbti_voice_eval.py from GitHub\n",
      "\n",
      "üîÑ Starting experiment execution...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error running experiment: 'NoneType' object has no attribute '__dict__'\n",
      "\n",
      "üí° Fallback: You can run it manually with:\n",
      "   !python mbti_voice_eval.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2286/3441200319.py\", line 50, in <module>\n",
      "    spec.loader.exec_module(module)\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/home/runner/work/mbti-faculty-voice-research/mbti-faculty-voice-research/mbti_voice_eval.py\", line 119, in <module>\n",
      "    @dataclass(frozen=True)\n",
      "     ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/dataclasses.py\", line 1222, in wrap\n",
      "    return _process_class(cls, init, repr, eq, order, unsafe_hash,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/dataclasses.py\", line 947, in _process_class\n",
      "    and _is_type(type, cls, dataclasses, dataclasses.KW_ONLY,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/dataclasses.py\", line 712, in _is_type\n",
      "    ns = sys.modules.get(cls.__module__).__dict__\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute '__dict__'\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Load existing results (if available)\n",
    "# Uncomment to skip experiment and use existing results\n",
    "# import pandas as pd\n",
    "# df = pd.read_csv('mbti_voice_results.csv')\n",
    "# df = df[df['voice_accuracy'] != -1]\n",
    "# print(f\"‚úÖ Loaded {len(df)} existing results\")\n",
    "# skip_experiment = True\n",
    "\n",
    "skip_experiment = False  # Set to True to skip running the experiment\n",
    "\n",
    "if not skip_experiment:\n",
    "    print(\"üöÄ Running MBTI Voice Accuracy Experiment...\")\n",
    "    print(\"   This will test 10 personae √ó 16 MBTI types √ó 3 prompts = 480 trials\")\n",
    "    print(\"   This may take 15-30 minutes depending on API response times.\\n\")\n",
    "    \n",
    "    # Upload the experiment script from GitHub or use it directly\n",
    "    # For now, we'll download it from the repo\n",
    "    import requests\n",
    "    \n",
    "    try:\n",
    "        # Download the experiment script from GitHub\n",
    "        script_url = \"https://raw.githubusercontent.com/InquiryInstitute/mbti-faculty-voice-research/main/mbti_voice_eval.py\"\n",
    "        response = requests.get(script_url)\n",
    "        if response.status_code == 200:\n",
    "            with open('mbti_voice_eval.py', 'w') as f:\n",
    "                f.write(response.text)\n",
    "            print(\"‚úÖ Downloaded mbti_voice_eval.py from GitHub\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  Could not download script from GitHub. Please upload mbti_voice_eval.py manually.\")\n",
    "            print(\"   You can upload it via: Files ‚Üí Upload to session storage\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Error downloading script: {e}\")\n",
    "        print(\"   Please upload mbti_voice_eval.py manually via Files ‚Üí Upload\")\n",
    "    \n",
    "    # Now run the experiment\n",
    "    print(\"\\nüîÑ Starting experiment execution...\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Import and run the experiment\n",
    "        import sys\n",
    "        import importlib.util\n",
    "        \n",
    "        if os.path.exists('mbti_voice_eval.py'):\n",
    "            spec = importlib.util.spec_from_file_location(\"mbti_voice_eval\", \"mbti_voice_eval.py\")\n",
    "            if spec is None or spec.loader is None:\n",
    "                raise ImportError(\"Failed to create module spec for mbti_voice_eval.py\")\n",
    "            module = importlib.util.module_from_spec(spec)\n",
    "            # Add the current directory to sys.path for any imports\n",
    "            sys.path.insert(0, os.path.dirname(os.path.abspath('mbti_voice_eval.py')))\n",
    "            spec.loader.exec_module(module)\n",
    "            \n",
    "            # Run the experiment\n",
    "            module.run_experiment()\n",
    "            print(\"\\n‚úÖ Experiment completed! Results saved to mbti_voice_results.csv and mbti_voice_results.jsonl\")\n",
    "        else:\n",
    "            print(\"‚ùå mbti_voice_eval.py not found. Please upload it manually.\")\n",
    "            print(\"   Option 1: Upload via Files ‚Üí Upload to session storage\")\n",
    "            print(\"   Option 2: Run: !wget https://raw.githubusercontent.com/InquiryInstitute/mbti-faculty-voice-research/main/mbti_voice_eval.py\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error running experiment: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        print(\"\\nüí° Fallback: You can run it manually with:\")\n",
    "        print(\"   !python mbti_voice_eval.py\")\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  Skipping experiment - using existing results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze Results and Generate Visualizations\n",
    "\n",
    "Analyze the experiment results and create tables and graphs for inclusion in the essay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:02:02.313830Z",
     "iopub.status.busy": "2026-01-14T04:02:02.313627Z",
     "iopub.status.idle": "2026-01-14T04:02:04.101345Z",
     "shell.execute_reply": "2026-01-14T04:02:04.100304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  No results file found. Run the experiment first.\n",
      "‚ö†Ô∏è  No results to analyze. Please run the experiment first.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# Set style for better-looking plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "def load_results(jsonl_path=\"mbti_voice_results.jsonl\", csv_path=\"mbti_voice_results.csv\"):\n",
    "    \"\"\"Load experiment results from JSONL or CSV.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Try JSONL first\n",
    "    try:\n",
    "        with open(jsonl_path, 'r') as f:\n",
    "            for line in f:\n",
    "                record = json.loads(line)\n",
    "                if record.get('voice_accuracy') and record.get('voice_accuracy') != -1:\n",
    "                    results.append(record)\n",
    "        print(f\"‚úÖ Loaded {len(results)} valid results from {jsonl_path}\")\n",
    "        return results\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    \n",
    "    # Try CSV\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        # Filter valid results\n",
    "        df_valid = df[df['voice_accuracy'] != -1]\n",
    "        results = df_valid.to_dict('records')\n",
    "        print(f\"‚úÖ Loaded {len(results)} valid results from {csv_path}\")\n",
    "        return results\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ö†Ô∏è  No results file found. Run the experiment first.\")\n",
    "        return []\n",
    "\n",
    "# Load results\n",
    "results = load_results()\n",
    "\n",
    "if results:\n",
    "    df = pd.DataFrame(results)\n",
    "    print(f\"\\nüìä Dataset Summary:\")\n",
    "    print(f\"   Total valid trials: {len(df)}\")\n",
    "    print(f\"   Personae: {df['persona_name'].nunique()}\")\n",
    "    print(f\"   MBTI types: {df['mbti'].nunique()}\")\n",
    "    print(f\"   Average voice accuracy: {df['voice_accuracy'].mean():.2f}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No results to analyze. Please run the experiment first.\")\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:02:04.103719Z",
     "iopub.status.busy": "2026-01-14T04:02:04.103490Z",
     "iopub.status.idle": "2026-01-14T04:02:04.120099Z",
     "shell.execute_reply": "2026-01-14T04:02:04.119240Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  No data to summarize\n"
     ]
    }
   ],
   "source": [
    "if df is not None and len(df) > 0:\n",
    "    # Convert numeric columns\n",
    "    numeric_cols = ['voice_accuracy', 'style_marker_coverage', 'persona_consistency', \n",
    "                     'clarity', 'overfitting_to_mbti']\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    # Create summary statistics table\n",
    "    print(\"=\" * 60)\n",
    "    print(\"SUMMARY STATISTICS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    summary_stats = df[numeric_cols].describe()\n",
    "    print(\"\\nOverall Statistics:\")\n",
    "    print(summary_stats.round(2))\n",
    "    \n",
    "    # By MBTI type\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"BY MBTI TYPE\")\n",
    "    print(\"=\" * 60)\n",
    "    mbti_stats = df.groupby('mbti')['voice_accuracy'].agg(['mean', 'std', 'count']).round(2)\n",
    "    mbti_stats.columns = ['Mean Accuracy', 'Std Dev', 'Count']\n",
    "    mbti_stats = mbti_stats.sort_values('Mean Accuracy', ascending=False)\n",
    "    print(mbti_stats)\n",
    "    \n",
    "    # By Persona\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"BY PERSONA\")\n",
    "    print(\"=\" * 60)\n",
    "    persona_stats = df.groupby('persona_name')['voice_accuracy'].agg(['mean', 'std', 'count']).round(2)\n",
    "    persona_stats.columns = ['Mean Accuracy', 'Std Dev', 'Count']\n",
    "    persona_stats = persona_stats.sort_values('Mean Accuracy', ascending=False)\n",
    "    print(persona_stats)\n",
    "    \n",
    "    # Save summary tables\n",
    "    mbti_stats.to_csv('mbti_summary_table.csv')\n",
    "    persona_stats.to_csv('persona_summary_table.csv')\n",
    "    print(\"\\n‚úÖ Summary tables saved to CSV files\")\n",
    "    \n",
    "    # Generate comprehensive results analysis for LLM\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"GENERATING COMPREHENSIVE RESULTS ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Find best/worst performers\n",
    "    best_persona = persona_stats.index[0]\n",
    "    worst_persona = persona_stats.index[-1]\n",
    "    best_mbti = mbti_stats.index[0]\n",
    "    worst_mbti = mbti_stats.index[-1]\n",
    "    \n",
    "    # Calculate correlations\n",
    "    correlations = df[['voice_accuracy', 'style_marker_coverage', 'persona_consistency', \n",
    "                       'clarity', 'overfitting_to_mbti']].corr()['voice_accuracy'].sort_values(ascending=False)\n",
    "    \n",
    "    # Generate detailed analysis text\n",
    "    results_analysis = f\"\"\"\n",
    "EXPERIMENTAL RESULTS ANALYSIS\n",
    "==============================\n",
    "\n",
    "Dataset Overview:\n",
    "- Total valid trials: {len(df)}\n",
    "- Personae tested: {df['persona_name'].nunique()}\n",
    "- MBTI types tested: {df['mbti'].nunique()}\n",
    "- Prompts per combination: {len(df) // (df['persona_name'].nunique() * df['mbti'].nunique())}\n",
    "\n",
    "Overall Performance:\n",
    "- Average voice accuracy: {df['voice_accuracy'].mean():.2f} (range: {df['voice_accuracy'].min():.2f} - {df['voice_accuracy'].max():.2f})\n",
    "- Average persona consistency: {df['persona_consistency'].mean():.2f}\n",
    "- Average style marker coverage: {df['style_marker_coverage'].mean():.2f}\n",
    "- Average MBTI overfitting: {df['overfitting_to_mbti'].mean():.2f}\n",
    "\n",
    "Top Performers:\n",
    "- Best persona: {best_persona} (mean accuracy: {persona_stats.loc[best_persona, 'Mean Accuracy']:.2f})\n",
    "- Best MBTI type: {best_mbti} (mean accuracy: {mbti_stats.loc[best_mbti, 'Mean Accuracy']:.2f})\n",
    "\n",
    "Lowest Performers:\n",
    "- Worst persona: {worst_persona} (mean accuracy: {persona_stats.loc[worst_persona, 'Mean Accuracy']:.2f})\n",
    "- Worst MBTI type: {worst_mbti} (mean accuracy: {mbti_stats.loc[worst_mbti, 'Mean Accuracy']:.2f})\n",
    "\n",
    "Key Correlations with Voice Accuracy:\n",
    "{chr(10).join([f\"- {metric}: {corr:.3f}\" for metric, corr in correlations.items() if metric != 'voice_accuracy'])}\n",
    "\n",
    "MBTI Type Performance (Top 5):\n",
    "{chr(10).join([f\"- {mbti}: {mbti_stats.loc[mbti, 'Mean Accuracy']:.2f} (n={int(mbti_stats.loc[mbti, 'Count'])})\" for mbti in mbti_stats.head(5).index])}\n",
    "\n",
    "Persona Performance (Top 5):\n",
    "{chr(10).join([f\"- {persona}: {persona_stats.loc[persona, 'Mean Accuracy']:.2f} (n={int(persona_stats.loc[persona, 'Count'])})\" for persona in persona_stats.head(5).index])}\n",
    "\n",
    "Statistical Insights:\n",
    "- Standard deviation of voice accuracy: {df['voice_accuracy'].std():.2f}\n",
    "- Trials with high overfitting (score > 3): {len(df[df['overfitting_to_mbti'] > 3])} ({len(df[df['overfitting_to_mbti'] > 3])/len(df)*100:.1f}%)\n",
    "- Trials with high consistency (score >= 4): {len(df[df['persona_consistency'] >= 4])} ({len(df[df['persona_consistency'] >= 4])/len(df)*100:.1f}%)\n",
    "\"\"\"\n",
    "    \n",
    "    # Statistical hypothesis testing\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"STATISTICAL HYPOTHESIS TESTING\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    from scipy import stats\n",
    "    import numpy as np\n",
    "    \n",
    "    # Hypothesis 1: MBTI overlays improve voice accuracy\n",
    "    # H0: Mean voice accuracy with MBTI = Mean voice accuracy without MBTI (baseline)\n",
    "    # H1: Mean voice accuracy with MBTI > Mean voice accuracy without MBTI\n",
    "    \n",
    "    # For this test, we'll compare MBTI types to see if there's significant variation\n",
    "    # and compare top performers vs bottom performers\n",
    "    \n",
    "    # Test 1: One-way ANOVA - Do MBTI types differ significantly in voice accuracy?\n",
    "    mbti_groups = [df[df['mbti'] == mbti]['voice_accuracy'].values for mbti in df['mbti'].unique()]\n",
    "    f_stat, p_value_anova = stats.f_oneway(*mbti_groups)\n",
    "    \n",
    "    # Test 2: T-test - Do top 25% MBTI types perform significantly better than bottom 25%?\n",
    "    top_quartile_threshold = df.groupby('mbti')['voice_accuracy'].mean().quantile(0.75)\n",
    "    bottom_quartile_threshold = df.groupby('mbti')['voice_accuracy'].mean().quantile(0.25)\n",
    "    \n",
    "    top_mbti_types = df.groupby('mbti')['voice_accuracy'].mean()[df.groupby('mbti')['voice_accuracy'].mean() >= top_quartile_threshold].index\n",
    "    bottom_mbti_types = df.groupby('mbti')['voice_accuracy'].mean()[df.groupby('mbti')['voice_accuracy'].mean() <= bottom_quartile_threshold].index\n",
    "    \n",
    "    top_scores = df[df['mbti'].isin(top_mbti_types)]['voice_accuracy'].values\n",
    "    bottom_scores = df[df['mbti'].isin(bottom_mbti_types)]['voice_accuracy'].values\n",
    "    \n",
    "    t_stat, p_value_ttest = stats.ttest_ind(top_scores, bottom_scores, alternative='greater')\n",
    "    \n",
    "    # Test 3: Correlation test - Is there a significant correlation between style coverage and accuracy?\n",
    "    corr_coef, p_value_corr = stats.pearsonr(df['style_marker_coverage'], df['voice_accuracy'])\n",
    "    \n",
    "    # Test 4: Effect size (Cohen's d) for top vs bottom MBTI types\n",
    "    pooled_std = np.sqrt(((len(top_scores) - 1) * top_scores.std()**2 + (len(bottom_scores) - 1) * bottom_scores.std()**2) / (len(top_scores) + len(bottom_scores) - 2))\n",
    "    cohens_d = (top_scores.mean() - bottom_scores.mean()) / pooled_std if pooled_std > 0 else 0\n",
    "    \n",
    "    # Generate hypothesis testing results\n",
    "    hypothesis_results = f\"\"\"\n",
    "\n",
    "STATISTICAL HYPOTHESIS TESTING RESULTS\n",
    "======================================\n",
    "\n",
    "Primary Hypothesis: MBTI overlays improve voice accuracy in faculty agents.\n",
    "\n",
    "Test 1: ANOVA - Do MBTI types differ significantly in voice accuracy?\n",
    "- F-statistic: {f_stat:.4f}\n",
    "- p-value: {p_value_anova:.6f}\n",
    "- Result: {'REJECT H0' if p_value_anova < 0.05 else 'FAIL TO REJECT H0'} - {'MBTI types show significant variation' if p_value_anova < 0.05 else 'No significant variation between MBTI types'}\n",
    "- Interpretation: {'There is statistically significant evidence that MBTI types produce different voice accuracy scores (p < 0.05)' if p_value_anova < 0.05 else 'No statistically significant evidence that MBTI types differ in voice accuracy (p >= 0.05)'}\n",
    "\n",
    "Test 2: Independent T-test - Do top-performing MBTI types significantly outperform bottom performers?\n",
    "- Top quartile MBTI types: {', '.join(top_mbti_types[:5])}\n",
    "- Bottom quartile MBTI types: {', '.join(bottom_mbti_types[:5])}\n",
    "- Top quartile mean: {top_scores.mean():.3f} (n={len(top_scores)})\n",
    "- Bottom quartile mean: {bottom_scores.mean():.3f} (n={len(bottom_scores)})\n",
    "- Mean difference: {top_scores.mean() - bottom_scores.mean():.3f}\n",
    "- t-statistic: {t_stat:.4f}\n",
    "- p-value: {p_value_ttest:.6f}\n",
    "- Result: {'REJECT H0' if p_value_ttest < 0.05 else 'FAIL TO REJECT H0'} - {'Top MBTI types significantly outperform bottom types' if p_value_ttest < 0.05 else 'No significant difference between top and bottom MBTI types'}\n",
    "- Effect size (Cohen's d): {cohens_d:.3f} ({'large' if abs(cohens_d) > 0.8 else 'medium' if abs(cohens_d) > 0.5 else 'small'} effect)\n",
    "- Interpretation: {'Top-performing MBTI types produce significantly higher voice accuracy scores than bottom performers (p < 0.05)' if p_value_ttest < 0.05 else 'No statistically significant difference between top and bottom MBTI types (p >= 0.05)'}\n",
    "\n",
    "Test 3: Pearson Correlation - Relationship between style marker coverage and voice accuracy\n",
    "- Correlation coefficient: {corr_coef:.4f}\n",
    "- p-value: {p_value_corr:.6f}\n",
    "- Result: {'SIGNIFICANT CORRELATION' if p_value_corr < 0.05 else 'NO SIGNIFICANT CORRELATION'}\n",
    "- Interpretation: {'There is a statistically significant correlation between style marker coverage and voice accuracy (p < 0.05)' if p_value_corr < 0.05 else 'No statistically significant correlation between style marker coverage and voice accuracy (p >= 0.05)'}\n",
    "\n",
    "Overall Hypothesis Validation:\n",
    "- Primary hypothesis {'SUPPORTED' if (p_value_anova < 0.05 and p_value_ttest < 0.05) else 'PARTIALLY SUPPORTED' if p_value_anova < 0.05 else 'NOT SUPPORTED'}: {'MBTI overlays show statistically significant effects on voice accuracy' if (p_value_anova < 0.05 and p_value_ttest < 0.05) else 'MBTI overlays show some variation but limited evidence of systematic improvement' if p_value_anova < 0.05 else 'No statistically significant evidence that MBTI overlays improve voice accuracy'}\n",
    "- Statistical significance level: Œ± = 0.05\n",
    "\"\"\"\n",
    "    \n",
    "    print(hypothesis_results)\n",
    "    \n",
    "    # Append hypothesis testing to results analysis\n",
    "    results_analysis += hypothesis_results\n",
    "    \n",
    "    # Save analysis to file\n",
    "    with open('results_analysis.txt', 'w') as f:\n",
    "        f.write(results_analysis)\n",
    "    \n",
    "    # Save hypothesis testing results separately\n",
    "    with open('hypothesis_testing_results.txt', 'w') as f:\n",
    "        f.write(hypothesis_results)\n",
    "    \n",
    "    print(\"\\n‚úÖ Comprehensive analysis saved to results_analysis.txt\")\n",
    "    print(\"‚úÖ Hypothesis testing results saved to hypothesis_testing_results.txt\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No data to summarize\")\n",
    "    results_analysis = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:02:04.122602Z",
     "iopub.status.busy": "2026-01-14T04:02:04.122329Z",
     "iopub.status.idle": "2026-01-14T04:02:04.131158Z",
     "shell.execute_reply": "2026-01-14T04:02:04.130237Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  No data to visualize\n"
     ]
    }
   ],
   "source": [
    "if df is not None and len(df) > 0:\n",
    "    # Figure 1: Voice Accuracy Distribution\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # 1. Histogram of voice accuracy\n",
    "    axes[0, 0].hist(df['voice_accuracy'], bins=20, edgecolor='black', alpha=0.7)\n",
    "    axes[0, 0].axvline(df['voice_accuracy'].mean(), color='red', linestyle='--', \n",
    "                       label=f'Mean: {df[\"voice_accuracy\"].mean():.2f}')\n",
    "    axes[0, 0].set_xlabel('Voice Accuracy Score')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    axes[0, 0].set_title('Distribution of Voice Accuracy Scores')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Voice Accuracy by MBTI Type\n",
    "    mbti_order = df.groupby('mbti')['voice_accuracy'].mean().sort_values(ascending=False).index\n",
    "    mbti_means = df.groupby('mbti')['voice_accuracy'].mean().reindex(mbti_order)\n",
    "    axes[0, 1].barh(range(len(mbti_means)), mbti_means.values)\n",
    "    axes[0, 1].set_yticks(range(len(mbti_means)))\n",
    "    axes[0, 1].set_yticklabels(mbti_means.index)\n",
    "    axes[0, 1].set_xlabel('Mean Voice Accuracy')\n",
    "    axes[0, 1].set_title('Voice Accuracy by MBTI Type')\n",
    "    axes[0, 1].grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # 3. Voice Accuracy by Persona\n",
    "    persona_order = df.groupby('persona_name')['voice_accuracy'].mean().sort_values(ascending=False).index\n",
    "    persona_means = df.groupby('persona_name')['voice_accuracy'].mean().reindex(persona_order)\n",
    "    axes[1, 0].barh(range(len(persona_means)), persona_means.values)\n",
    "    axes[1, 0].set_yticks(range(len(persona_means)))\n",
    "    axes[1, 0].set_yticklabels(persona_means.index, fontsize=8)\n",
    "    axes[1, 0].set_xlabel('Mean Voice Accuracy')\n",
    "    axes[1, 0].set_title('Voice Accuracy by Persona')\n",
    "    axes[1, 0].grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # 4. Box plot: Voice Accuracy by MBTI\n",
    "    df_sorted = df.copy()\n",
    "    df_sorted['mbti'] = pd.Categorical(df_sorted['mbti'], categories=mbti_order)\n",
    "    sns.boxplot(data=df_sorted, y='mbti', x='voice_accuracy', ax=axes[1, 1])\n",
    "    axes[1, 1].set_xlabel('Voice Accuracy Score')\n",
    "    axes[1, 1].set_ylabel('MBTI Type')\n",
    "    axes[1, 1].set_title('Voice Accuracy Distribution by MBTI Type')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('voice_accuracy_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"‚úÖ Saved: voice_accuracy_analysis.png\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No data to visualize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:02:04.132937Z",
     "iopub.status.busy": "2026-01-14T04:02:04.132747Z",
     "iopub.status.idle": "2026-01-14T04:02:04.140309Z",
     "shell.execute_reply": "2026-01-14T04:02:04.139516Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  No data to visualize\n"
     ]
    }
   ],
   "source": [
    "if df is not None and len(df) > 0:\n",
    "    # Figure 2: Correlation and Multi-metric Analysis\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # 1. Correlation heatmap\n",
    "    corr_cols = ['voice_accuracy', 'style_marker_coverage', 'persona_consistency', \n",
    "                 'clarity', 'overfitting_to_mbti']\n",
    "    corr_data = df[corr_cols].corr()\n",
    "    sns.heatmap(corr_data, annot=True, fmt='.2f', cmap='coolwarm', center=0, \n",
    "                square=True, ax=axes[0, 0])\n",
    "    axes[0, 0].set_title('Correlation Matrix of Evaluation Metrics')\n",
    "    \n",
    "    # 2. Style Marker Coverage vs Voice Accuracy\n",
    "    axes[0, 1].scatter(df['style_marker_coverage'], df['voice_accuracy'], alpha=0.5)\n",
    "    axes[0, 1].set_xlabel('Style Marker Coverage')\n",
    "    axes[0, 1].set_ylabel('Voice Accuracy')\n",
    "    axes[0, 1].set_title('Style Coverage vs Voice Accuracy')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Persona Consistency vs Voice Accuracy\n",
    "    axes[1, 0].scatter(df['persona_consistency'], df['voice_accuracy'], alpha=0.5)\n",
    "    axes[1, 0].set_xlabel('Persona Consistency')\n",
    "    axes[1, 0].set_ylabel('Voice Accuracy')\n",
    "    axes[1, 0].set_title('Persona Consistency vs Voice Accuracy')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. MBTI Overfitting Distribution\n",
    "    axes[1, 1].hist(df['overfitting_to_mbti'], bins=15, edgecolor='black', alpha=0.7)\n",
    "    axes[1, 1].axvline(df['overfitting_to_mbti'].mean(), color='red', linestyle='--',\n",
    "                       label=f'Mean: {df[\"overfitting_to_mbti\"].mean():.2f}')\n",
    "    axes[1, 1].set_xlabel('MBTI Overfitting Score')\n",
    "    axes[1, 1].set_ylabel('Frequency')\n",
    "    axes[1, 1].set_title('Distribution of MBTI Overfitting Scores')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('metrics_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"‚úÖ Saved: metrics_analysis.png\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No data to visualize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:02:04.142137Z",
     "iopub.status.busy": "2026-01-14T04:02:04.141937Z",
     "iopub.status.idle": "2026-01-14T04:02:04.147544Z",
     "shell.execute_reply": "2026-01-14T04:02:04.146531Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  No data to visualize\n"
     ]
    }
   ],
   "source": [
    "if df is not None and len(df) > 0:\n",
    "    # Figure 3: Heatmap of Persona x MBTI Performance\n",
    "    pivot_data = df.pivot_table(\n",
    "        values='voice_accuracy',\n",
    "        index='persona_name',\n",
    "        columns='mbti',\n",
    "        aggfunc='mean'\n",
    "    )\n",
    "    \n",
    "    plt.figure(figsize=(16, 10))\n",
    "    sns.heatmap(pivot_data, annot=True, fmt='.2f', cmap='YlOrRd', \n",
    "                cbar_kws={'label': 'Mean Voice Accuracy'}, linewidths=0.5)\n",
    "    plt.title('Voice Accuracy: Persona √ó MBTI Type Heatmap', fontsize=14, pad=20)\n",
    "    plt.xlabel('MBTI Type', fontsize=12)\n",
    "    plt.ylabel('Persona', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('persona_mbti_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"‚úÖ Saved: persona_mbti_heatmap.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Save pivot table as CSV\n",
    "    pivot_data.to_csv('persona_mbti_heatmap_data.csv')\n",
    "    print(\"‚úÖ Saved: persona_mbti_heatmap_data.csv\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No data to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate Ada Lovelace Essay with Results Analysis\n",
    "\n",
    "Generate the essay incorporating analysis of the experimental results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Download Generated Files\n",
    "\n",
    "Download all generated files including the essay, tables, and visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:02:04.149812Z",
     "iopub.status.busy": "2026-01-14T04:02:04.149599Z",
     "iopub.status.idle": "2026-01-14T04:02:04.870353Z",
     "shell.execute_reply": "2026-01-14T04:02:04.869219Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  No results available - generating essay without experimental data\n",
      "Generating essay by Ada Lovelace...\n",
      "Using model: openai/gpt-4o\n",
      "\n"
     ]
    },
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': \"You didn't provide an API key. You need to provide your API key in an Authorization header using Bearer auth (i.e. Authorization: Bearer YOUR_KEY), or as the password field (with blank username) if you're accessing the API from your browser and are prompted for a username and password. You can obtain an API key from https://platform.openai.com/account/api-keys.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAuthenticationError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 156\u001b[39m\n\u001b[32m    153\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚ö†Ô∏è  No results available - generating essay without experimental data\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    155\u001b[39m \u001b[38;5;66;03m# Generate the essay with comprehensive results analysis\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m essay_content = \u001b[43mgenerate_lovelace_essay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults_summary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m‚úÖ Essay generated with results analysis!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 98\u001b[39m, in \u001b[36mgenerate_lovelace_essay\u001b[39m\u001b[34m(results_summary)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mGenerating essay by Ada Lovelace...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     96\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUsing model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4000\u001b[39;49m\n\u001b[32m    103\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    105\u001b[39m essay = response.choices[\u001b[32m0\u001b[39m].message.content\n\u001b[32m    107\u001b[39m \u001b[38;5;66;03m# Format as markdown\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/openai/_utils/_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py:1192\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1145\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1146\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1147\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1189\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m   1190\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1191\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1197\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1198\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1199\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1200\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1201\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1203\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1204\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1205\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1206\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1207\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1208\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1209\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1210\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1211\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1212\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1213\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_retention\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_retention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1214\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1215\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1216\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1217\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1218\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1219\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1220\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1221\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1225\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1226\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1227\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1228\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1229\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1230\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1231\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1232\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1233\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1235\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1236\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1237\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1238\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1240\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1242\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/openai/_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAuthenticationError\u001b[39m: Error code: 401 - {'error': {'message': \"You didn't provide an API key. You need to provide your API key in an Authorization header using Bearer auth (i.e. Authorization: Bearer YOUR_KEY), or as the password field (with blank username) if you're accessing the API from your browser and are prompted for a username and password. You can obtain an API key from https://platform.openai.com/account/api-keys.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "# Setup OpenAI client for OpenRouter\n",
    "def openai_client():\n",
    "    api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "    base_url = \"https://openrouter.ai/api/v1\"\n",
    "    \n",
    "    if api_key and api_key.startswith(\"sk-or-v1-\"):\n",
    "        return OpenAI(\n",
    "            api_key=api_key,\n",
    "            base_url=base_url,\n",
    "            default_headers={\n",
    "                \"HTTP-Referer\": \"https://colab.research.google.com\",\n",
    "                \"X-Title\": \"MBTI Faculty Voice Research\"\n",
    "            }\n",
    "        )\n",
    "    return OpenAI(api_key=api_key)\n",
    "\n",
    "client = openai_client()\n",
    "\n",
    "def generate_lovelace_essay(results_summary=None):\n",
    "    \"\"\"Generate essay by Ada Lovelace on MBTI research, incorporating results analysis.\"\"\"\n",
    "    model = os.getenv(\"OPENAI_MODEL\", \"openai/gpt-4o\")\n",
    "    \n",
    "    # Build results context if available\n",
    "    results_context = \"\"\n",
    "    if results_summary:\n",
    "        results_context = f\"\"\"\n",
    "\n",
    "EXPERIMENTAL RESULTS AND ANALYSIS:\n",
    "{results_summary}\n",
    "\n",
    "CRITICAL: You must thoroughly analyze these experimental results and incorporate them into your essay. This is not optional - the results are the core of the research.\n",
    "\n",
    "Your analysis should:\n",
    "1. **Interpret the findings**: What do the numbers tell us about MBTI's effectiveness?\n",
    "2. **Identify patterns**: Are there clear winners/losers? What explains the differences?\n",
    "3. **Evaluate MBTI's utility**: Does the data support or challenge MBTI as a prompt engineering tool?\n",
    "4. **Discuss implications**: What does this mean for creating faculty agents?\n",
    "5. **Acknowledge limitations**: What can't we conclude from this data?\n",
    "6. **Consider correlations**: How do style coverage, consistency, and overfitting relate to accuracy?\n",
    "\n",
    "Be specific: Reference actual numbers, rankings, and patterns from the data. This is a data-driven essay, not just philosophical reflection.\n",
    "\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"You are Ada Lovelace, writing a scientific commonplace essay on the investigation of MBTI's value in prompt engineering for faculty agent accuracy.\n",
    "\n",
    "Context: This research examines whether Myers-Briggs Type Indicator (MBTI) personality overlays improve voice accuracy, consistency, and interpretability in AI faculty agents. The experiment tests 10 faculty personae across 16 MBTI types with 3 test prompts each (480 trials total), using an LLM-as-judge to evaluate voice accuracy.{results_context}\n",
    "\n",
    "CRITICAL STRUCTURE REQUIREMENT: You must structure this essay following the scientific method:\n",
    "\n",
    "1. **Abstract/Background & Hypothesis**: \n",
    "   - Begin with a clear research question\n",
    "   - State a testable hypothesis (e.g., \"MBTI overlays will significantly improve voice accuracy compared to baseline\" or \"Certain MBTI types will produce measurably higher voice accuracy scores\")\n",
    "   - Explain the theoretical basis for this hypothesis\n",
    "   - Frame this in terms of symbolic systems and computational mechanisms\n",
    "\n",
    "2. **Methods**:\n",
    "   - Describe the experimental design (10 personae √ó 16 MBTI types √ó 3 prompts = 480 trials)\n",
    "   - Explain the evaluation methodology (LLM-as-judge)\n",
    "   - Note the statistical tests used (ANOVA, t-tests, correlation analysis)\n",
    "\n",
    "3. **Results & Statistical Validation**:\n",
    "   - Present the experimental findings\n",
    "   - Report statistical test results (F-statistics, t-statistics, p-values, effect sizes)\n",
    "   - Clearly state whether the hypothesis is SUPPORTED, PARTIALLY SUPPORTED, or NOT SUPPORTED\n",
    "   - Include specific numerical evidence\n",
    "\n",
    "4. **Discussion & Conclusion**:\n",
    "   - Interpret what the statistical validation means\n",
    "   - Discuss whether MBTI functions effectively as a \"prompt compression ontology\"\n",
    "   - Consider implications for creating coherent, persistent agent identities\n",
    "   - Acknowledge limitations and areas for further investigation\n",
    "   - Reflect on the relationship between symbolic systems and computational mechanisms\n",
    "\n",
    "Your task: Write a thoughtful, elegant scientific essay (2000-3000 words) that:\n",
    "- Follows the scientific method structure above\n",
    "- States a clear hypothesis in the abstract/background\n",
    "- Uses statistical results to validate or invalidate that hypothesis\n",
    "- Maintains your characteristic voice: elegant, analytical, visionary about computation's scope, precise but imaginative, with a \"poetical science\" sensibility\n",
    "- Uses your signature moves: clarify mechanism vs meaning, structured explanation, poetical science sensibility\n",
    "- Avoids modern dev slang, casual tone, or pretending firsthand modern tooling\n",
    "\n",
    "Write in the style of your era (Victorian scientific culture) but addressing contemporary AI systems. Be thoughtful, precise, and allow for the imaginative possibilities while maintaining analytical rigor. The essay must be data-driven and hypothesis-testing focused.\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"\"\"You are Ada Lovelace, the first computer programmer and a visionary of computation's potential. \n",
    "Your voice is elegant, analytical, visionary about computation's scope, precise but imaginative. \n",
    "You clarify mechanism vs meaning, provide structured explanations, and maintain a 'poetical science' sensibility.\n",
    "You write in the style of Victorian scientific culture, with careful distinctions and elegant prose.\"\"\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    \n",
    "    print(\"Generating essay by Ada Lovelace...\")\n",
    "    print(f\"Using model: {model}\\n\")\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0.8,\n",
    "        max_tokens=4000\n",
    "    )\n",
    "    \n",
    "    essay = response.choices[0].message.content\n",
    "    \n",
    "    # Format as markdown\n",
    "    formatted = f\"\"\"# On the Investigation of MBTI in Prompt Engineering for Faculty Agent Accuracy\n",
    "\n",
    "**Ada Lovelace**\n",
    "\n",
    "*A Commonplace Essay*\n",
    "\n",
    "---\n",
    "\n",
    "{essay}\"\"\"\n",
    "    \n",
    "    print(\"‚úÖ Essay generated!\")\n",
    "    print(f\"\\nPreview (first 500 chars):\\n{essay[:500]}...\")\n",
    "    \n",
    "    return formatted\n",
    "\n",
    "# Generate comprehensive results summary for essay\n",
    "results_summary = None\n",
    "if df is not None and len(df) > 0:\n",
    "    # Load the detailed analysis if available\n",
    "    try:\n",
    "        with open('results_analysis.txt', 'r') as f:\n",
    "            results_summary = f.read()\n",
    "        print(\"‚úÖ Loaded comprehensive results analysis\")\n",
    "    except FileNotFoundError:\n",
    "        # Fallback to basic summary\n",
    "        mbti_stats = df.groupby('mbti')['voice_accuracy'].agg(['mean', 'std', 'count']).round(2)\n",
    "        persona_stats = df.groupby('persona_name')['voice_accuracy'].agg(['mean', 'std', 'count']).round(2)\n",
    "        \n",
    "        results_summary = f\"\"\"\n",
    "Total valid trials: {len(df)}\n",
    "Average voice accuracy: {df['voice_accuracy'].mean():.2f} (range: {df['voice_accuracy'].min():.2f} - {df['voice_accuracy'].max():.2f})\n",
    "Average persona consistency: {df['persona_consistency'].mean():.2f}\n",
    "Average style marker coverage: {df['style_marker_coverage'].mean():.2f}\n",
    "Average MBTI overfitting: {df['overfitting_to_mbti'].mean():.2f}\n",
    "\n",
    "Top 3 MBTI types by voice accuracy:\n",
    "{df.groupby('mbti')['voice_accuracy'].mean().sort_values(ascending=False).head(3).to_string()}\n",
    "\n",
    "Top 3 personae by voice accuracy:\n",
    "{df.groupby('persona_name')['voice_accuracy'].mean().sort_values(ascending=False).head(3).to_string()}\n",
    "\"\"\"\n",
    "    \n",
    "    print(\"\\nüìä Generating essay with results analysis...\")\n",
    "    print(f\"   Analysis length: {len(results_summary)} characters\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No results available - generating essay without experimental data\")\n",
    "\n",
    "# Generate the essay with comprehensive results analysis\n",
    "essay_content = generate_lovelace_essay(results_summary)\n",
    "\n",
    "print(\"\\n‚úÖ Essay generated with results analysis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Upload to Commonplace\n",
    "\n",
    "Upload the essay to Inquiry Institute Commonplace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Update Essay with Results Analysis\n",
    "\n",
    "After generating visualizations and analysis, update the essay to incorporate the findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:02:04.872523Z",
     "iopub.status.busy": "2026-01-14T04:02:04.872320Z",
     "iopub.status.idle": "2026-01-14T04:02:04.877622Z",
     "shell.execute_reply": "2026-01-14T04:02:04.876769Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÑπÔ∏è  Using previously generated essay\n",
      "‚ö†Ô∏è  No essay content available - run essay generation cell first\n"
     ]
    }
   ],
   "source": [
    "# Re-generate essay with comprehensive analysis if results are available\n",
    "if df is not None and len(df) > 0 and 'results_analysis' in locals():\n",
    "    print(\"üîÑ Updating essay with comprehensive results analysis...\")\n",
    "    \n",
    "    # Load the full analysis\n",
    "    try:\n",
    "        with open('results_analysis.txt', 'r') as f:\n",
    "            full_analysis = f.read()\n",
    "        \n",
    "        # Generate updated essay with full analysis\n",
    "        updated_essay = generate_lovelace_essay(full_analysis)\n",
    "        \n",
    "        # Save updated essay\n",
    "        with open('lovelace_essay_mbti_research.md', 'w', encoding='utf-8') as f:\n",
    "            f.write(updated_essay)\n",
    "        \n",
    "        print(\"‚úÖ Essay updated with comprehensive results analysis!\")\n",
    "        print(\"   File: lovelace_essay_mbti_research.md\")\n",
    "        \n",
    "        # Update the essay_content variable\n",
    "        essay_content = updated_essay\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ö†Ô∏è  Results analysis file not found - using previously generated essay\")\n",
    "        print(\"   Run the analysis cells first to generate comprehensive analysis\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  Using previously generated essay\")\n",
    "    if 'essay_content' not in locals():\n",
    "        print(\"‚ö†Ô∏è  No essay content available - run essay generation cell first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:02:04.879659Z",
     "iopub.status.busy": "2026-01-14T04:02:04.879474Z",
     "iopub.status.idle": "2026-01-14T04:02:04.933350Z",
     "shell.execute_reply": "2026-01-14T04:02:04.932610Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'essay_content' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 133\u001b[39m\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.json()\n\u001b[32m    132\u001b[39m \u001b[38;5;66;03m# Extract title and content\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m title, content = extract_title_and_content(\u001b[43messay_content\u001b[49m)\n\u001b[32m    135\u001b[39m \u001b[38;5;66;03m# Upload (will prompt for JWT token)\u001b[39;00m\n\u001b[32m    136\u001b[39m upload_result = upload_to_commonplace(title, content)\n",
      "\u001b[31mNameError\u001b[39m: name 'essay_content' is not defined"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "\n",
    "def extract_title_and_content(markdown_text):\n",
    "    \"\"\"Extract title and content from markdown.\"\"\"\n",
    "    lines = markdown_text.split('\\n')\n",
    "    title = None\n",
    "    content_start = 0\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        if line.startswith('# '):\n",
    "            title = line[2:].strip()\n",
    "            content_start = i + 1\n",
    "            break\n",
    "    \n",
    "    if not title:\n",
    "        title = \"On the Investigation of MBTI in Prompt Engineering for Faculty Agent Accuracy\"\n",
    "    \n",
    "    essay_content = '\\n'.join(lines[content_start:])\n",
    "    essay_content = essay_content.replace('**Ada Lovelace**', '').replace('*A Commonplace Essay*', '').strip()\n",
    "    essay_content = essay_content.lstrip('-').strip()\n",
    "    \n",
    "    return title, essay_content\n",
    "\n",
    "def upload_to_commonplace(title, content, jwt_token=None, use_colab_endpoint=True):\n",
    "    \"\"\"\n",
    "    Upload essay to Commonplace via Supabase Edge Function.\n",
    "    \n",
    "    Uses the colab-commonplace endpoint which supports create/update/get operations.\n",
    "    \"\"\"\n",
    "    \n",
    "    supabase_url = os.getenv(\"NEXT_PUBLIC_SUPABASE_URL\")\n",
    "    supabase_anon_key = os.getenv(\"NEXT_PUBLIC_SUPABASE_ANON_KEY\")\n",
    "    \n",
    "    if not jwt_token:\n",
    "        jwt_token = getpass(\"Enter a.lovelace JWT token (or press Enter to skip upload): \").strip()\n",
    "        if not jwt_token:\n",
    "            print(\"‚ö†Ô∏è  Skipping upload. You can upload manually later.\")\n",
    "            return None\n",
    "    \n",
    "    # Use colab-commonplace endpoint (supports create/update/get)\n",
    "    edge_function_url = f\"{supabase_url}/functions/v1/colab-commonplace\"\n",
    "    \n",
    "    # Convert markdown to HTML (basic conversion)\n",
    "    html_content = content.replace('\\n\\n', '</p><p>').replace('\\n', '<br>')\n",
    "    html_content = f\"<p>{html_content}</p>\"\n",
    "    \n",
    "    payload = {\n",
    "        \"action\": \"create\",\n",
    "        \"entry\": {\n",
    "            \"title\": title,\n",
    "            \"content\": html_content,\n",
    "            \"status\": \"draft\",\n",
    "            \"faculty_slug\": \"a-lovelace\",\n",
    "            \"entry_type\": \"essay\",\n",
    "            \"topics\": [\"mbti\", \"prompt-engineering\", \"faculty-agents\", \"ai-research\"],\n",
    "            \"college\": \"ains\",\n",
    "            \"metadata\": {\n",
    "                \"provenance_mode\": \"ai_generated\",\n",
    "                \"canonical_source_url\": \"https://github.com/InquiryInstitute/Inquiry.Institute/tree/main/mbti-faculty-voice-research\",\n",
    "                \"colab_notebook_url\": \"https://colab.research.google.com/...\",\n",
    "                \"source_refs\": \"Generated by Ada Lovelace faculty agent via Google Colab\",\n",
    "                \"generated_by\": \"Ada Lovelace\",\n",
    "                \"pinned\": False\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {jwt_token}\",\n",
    "        \"apikey\": supabase_anon_key,\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    print(f\"üì§ Uploading essay to Commonplace...\")\n",
    "    print(f\"   Title: {title}\")\n",
    "    print(f\"   Faculty: a-lovelace\")\n",
    "    print(f\"   Status: draft\")\n",
    "    print(f\"   Endpoint: colab-commonplace\\n\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(edge_function_url, headers=headers, json=payload, timeout=30)\n",
    "        \n",
    "        if response.status_code == 201:\n",
    "            result = response.json()\n",
    "            if result.get(\"success\"):\n",
    "                print(\"‚úÖ Essay uploaded successfully!\")\n",
    "                entry = result.get(\"entry\", {})\n",
    "                print(f\"   Entry ID: {entry.get('id')}\")\n",
    "                print(f\"   Permalink: {entry.get('permalink', 'N/A')}\")\n",
    "                print(f\"   Status: {entry.get('status')}\")\n",
    "                print(f\"\\nüí° To update later, use entry ID: {entry.get('id')}\")\n",
    "                return result\n",
    "            else:\n",
    "                print(f\"‚ùå Upload failed: {result.get('error', 'Unknown error')}\")\n",
    "                return None\n",
    "        else:\n",
    "            error_data = response.json() if response.headers.get('content-type', '').startswith('application/json') else response.text\n",
    "            print(f\"‚ùå Upload failed: {response.status_code}\")\n",
    "            print(f\"   Error: {json.dumps(error_data, indent=2)}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Request failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def update_entry(entry_id, jwt_token=None, **updates):\n",
    "    \"\"\"Update an existing Commonplace entry.\"\"\"\n",
    "    supabase_url = os.getenv(\"NEXT_PUBLIC_SUPABASE_URL\")\n",
    "    supabase_anon_key = os.getenv(\"NEXT_PUBLIC_SUPABASE_ANON_KEY\")\n",
    "    \n",
    "    if not jwt_token:\n",
    "        jwt_token = getpass(\"Enter JWT token: \").strip()\n",
    "    \n",
    "    edge_function_url = f\"{supabase_url}/functions/v1/colab-commonplace\"\n",
    "    \n",
    "    payload = {\n",
    "        \"action\": \"update\",\n",
    "        \"entry_id\": entry_id,\n",
    "        \"entry\": updates\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {jwt_token}\",\n",
    "        \"apikey\": supabase_anon_key,\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    response = requests.put(edge_function_url, headers=headers, json=payload, timeout=30)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "# Extract title and content\n",
    "title, content = extract_title_and_content(essay_content)\n",
    "\n",
    "# Upload (will prompt for JWT token)\n",
    "upload_result = upload_to_commonplace(title, content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:02:04.935453Z",
     "iopub.status.busy": "2026-01-14T04:02:04.935249Z",
     "iopub.status.idle": "2026-01-14T04:02:04.965574Z",
     "shell.execute_reply": "2026-01-14T04:02:04.964692Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m files\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Save essay to file\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "# Save essay to file\n",
    "with open('lovelace_essay_mbti_research.md', 'w', encoding='utf-8') as f:\n",
    "    f.write(essay_content)\n",
    "\n",
    "print(\"‚úÖ Essay saved to lovelace_essay_mbti_research.md\")\n",
    "\n",
    "# List all generated files\n",
    "generated_files = [\n",
    "    'lovelace_essay_mbti_research.md',\n",
    "    'voice_accuracy_analysis.png',\n",
    "    'metrics_analysis.png',\n",
    "    'persona_mbti_heatmap.png',\n",
    "    'mbti_summary_table.csv',\n",
    "    'persona_summary_table.csv',\n",
    "    'persona_mbti_heatmap_data.csv'\n",
    "]\n",
    "\n",
    "print(\"\\nüì¶ Generated files:\")\n",
    "for fname in generated_files:\n",
    "    if os.path.exists(fname):\n",
    "        size = os.path.getsize(fname)\n",
    "        print(f\"   ‚úÖ {fname} ({size:,} bytes)\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è  {fname} (not found)\")\n",
    "\n",
    "print(\"\\nüí° To download files, run:\")\n",
    "print(\"   files.download('lovelace_essay_mbti_research.md')\")\n",
    "print(\"   files.download('voice_accuracy_analysis.png')\")\n",
    "print(\"   files.download('metrics_analysis.png')\")\n",
    "print(\"   files.download('persona_mbti_heatmap.png')\")\n",
    "\n",
    "# Uncomment to auto-download all:\n",
    "# for fname in generated_files:\n",
    "#     if os.path.exists(fname):\n",
    "#         files.download(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Create a New Research Notebook\n",
    "\n",
    "You can create additional research notebooks using the `create-colab-notebook` edge function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:02:04.967570Z",
     "iopub.status.busy": "2026-01-14T04:02:04.967400Z",
     "iopub.status.idle": "2026-01-14T04:02:04.974442Z",
     "shell.execute_reply": "2026-01-14T04:02:04.973584Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_research_notebook(title, template=\"mbti-research\", research_topic=None, description=None, jwt_token=None):\n",
    "    \"\"\"\n",
    "    Create a new research notebook via Supabase Edge Function.\n",
    "    \n",
    "    Templates:\n",
    "    - mbti-research: Pre-configured for MBTI voice accuracy research\n",
    "    - essay-generation: Template for generating essays in faculty voice\n",
    "    - experiment: General experiment template\n",
    "    - custom: Empty template\n",
    "    \"\"\"\n",
    "    if not jwt_token:\n",
    "        jwt_token = getpass(\"Enter JWT token: \").strip()\n",
    "        if not jwt_token:\n",
    "            print(\"‚ö†Ô∏è  JWT token required to create notebooks\")\n",
    "            return None\n",
    "    \n",
    "    supabase_url = os.getenv(\"NEXT_PUBLIC_SUPABASE_URL\")\n",
    "    supabase_anon_key = os.getenv(\"NEXT_PUBLIC_SUPABASE_ANON_KEY\")\n",
    "    \n",
    "    edge_function_url = f\"{supabase_url}/functions/v1/create-colab-notebook\"\n",
    "    \n",
    "    payload = {\n",
    "        \"title\": title,\n",
    "        \"template\": template,\n",
    "    }\n",
    "    \n",
    "    if research_topic:\n",
    "        payload[\"research_topic\"] = research_topic\n",
    "    if description:\n",
    "        payload[\"description\"] = description\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {jwt_token}\",\n",
    "        \"apikey\": supabase_anon_key,\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    print(f\"üìì Creating research notebook: {title}\")\n",
    "    print(f\"   Template: {template}\\n\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(edge_function_url, headers=headers, json=payload, timeout=30)\n",
    "        \n",
    "        if response.status_code == 201:\n",
    "            result = response.json()\n",
    "            if result.get(\"success\"):\n",
    "                print(\"‚úÖ Notebook created!\")\n",
    "                notebook_json = result.get(\"notebook_json\", \"{}\")\n",
    "                \n",
    "                # Save notebook\n",
    "                filename = f\"{title.lower().replace(' ', '_')}.ipynb\"\n",
    "                with open(filename, 'w', encoding='utf-8') as f:\n",
    "                    f.write(notebook_json)\n",
    "                \n",
    "                print(f\"üíæ Saved to: {filename}\")\n",
    "                print(f\"\\nüìù Next steps:\")\n",
    "                print(f\"   1. Download the .ipynb file\")\n",
    "                print(f\"   2. Upload to Google Colab: File ‚Üí Upload notebook\")\n",
    "                print(f\"   3. Or save to GitHub and open from there\")\n",
    "                \n",
    "                return result\n",
    "        else:\n",
    "            error_data = response.json() if response.headers.get('content-type', '').startswith('application/json') else response.text\n",
    "            print(f\"‚ùå Creation failed: {response.status_code}\")\n",
    "            print(f\"   Error: {json.dumps(error_data, indent=2)}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Request failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example: Create a new notebook\n",
    "# create_research_notebook(\n",
    "#     title=\"My Research Project\",\n",
    "#     template=\"experiment\",\n",
    "#     research_topic=\"Investigating voice accuracy in AI agents\",\n",
    "#     description=\"A notebook for my research project\"\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
