{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MBTI Faculty Voice Research - Google Colab\n",
        "\n",
        "This notebook contains:\n",
        "1. **MBTI Voice Accuracy Experiment** - Run the full 480-trial experiment\n",
        "2. **Ada Lovelace Essay Generation** - Generate essay on MBTI research\n",
        "3. **Upload to Commonplace** - Upload essay to Inquiry Institute Commonplace\n",
        "\n",
        "## Setup\n",
        "\n",
        "1. Install dependencies\n",
        "2. Set API keys (OpenRouter, Supabase)\n",
        "3. Run the cells below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q openai pydantic python-dotenv requests pandas matplotlib seaborn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configure API Keys\n",
        "\n",
        "Set your API keys below. For security, you can use Colab's secrets manager or set them directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Try to use Colab Secrets Manager (preferred method)\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    print(\"üîê Using Colab Secrets Manager...\")\n",
        "    \n",
        "    # Get secrets from Colab Secrets Manager\n",
        "    OPENROUTER_API_KEY = userdata.get('OPENROUTER_API_KEY')\n",
        "    SUPABASE_URL = userdata.get('SUPABASE_URL', 'https://xougqdomkoisrxdnagcj.supabase.co')\n",
        "    SUPABASE_ANON_KEY = userdata.get('SUPABASE_ANON_KEY')\n",
        "    \n",
        "    os.environ[\"OPENROUTER_API_KEY\"] = OPENROUTER_API_KEY\n",
        "    os.environ[\"NEXT_PUBLIC_SUPABASE_URL\"] = SUPABASE_URL\n",
        "    os.environ[\"NEXT_PUBLIC_SUPABASE_ANON_KEY\"] = SUPABASE_ANON_KEY\n",
        "    \n",
        "    print(\"‚úÖ API keys loaded from Colab Secrets!\")\n",
        "    \n",
        "except (ModuleNotFoundError, KeyError) as e:\n",
        "    # Fallback to manual input if not in Colab or secrets not set\n",
        "    print(\"‚ö†Ô∏è  Colab Secrets not available, using manual input...\")\n",
        "    print(\"üí° Tip: Set secrets in Colab using the üîë icon in the left sidebar\")\n",
        "    print(\"   Secrets to add: OPENROUTER_API_KEY, SUPABASE_URL, SUPABASE_ANON_KEY\\n\")\n",
        "    \n",
        "    from getpass import getpass\n",
        "    \n",
        "    # OpenRouter API Key (required for experiment and essay generation)\n",
        "    OPENROUTER_API_KEY = getpass(\"Enter OpenRouter API Key (sk-or-v1-...): \")\n",
        "    os.environ[\"OPENROUTER_API_KEY\"] = OPENROUTER_API_KEY\n",
        "    \n",
        "    # Supabase credentials (required for uploading to Commonplace)\n",
        "    SUPABASE_URL = input(\"Enter Supabase URL (https://xxx.supabase.co): \").strip() or \"https://xougqdomkoisrxdnagcj.supabase.co\"\n",
        "    os.environ[\"NEXT_PUBLIC_SUPABASE_URL\"] = SUPABASE_URL\n",
        "    \n",
        "    SUPABASE_ANON_KEY = getpass(\"Enter Supabase Anon Key: \")\n",
        "    os.environ[\"NEXT_PUBLIC_SUPABASE_ANON_KEY\"] = SUPABASE_ANON_KEY\n",
        "    \n",
        "    print(\"\\n‚úÖ API keys configured!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Run MBTI Voice Accuracy Experiment\n",
        "\n",
        "Run the full experiment or load existing results. The experiment tests 10 faculty personae across 16 MBTI types with 3 test prompts each (480 trials total)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Option 1: Load existing results (if available)\n",
        "# Uncomment to skip experiment and use existing results\n",
        "# import pandas as pd\n",
        "# df = pd.read_csv('mbti_voice_results.csv')\n",
        "# df = df[df['voice_accuracy'] != -1]\n",
        "# print(f\"‚úÖ Loaded {len(df)} existing results\")\n",
        "# skip_experiment = True\n",
        "\n",
        "skip_experiment = False  # Set to True to skip running the experiment\n",
        "\n",
        "if not skip_experiment:\n",
        "    print(\"üöÄ Running MBTI Voice Accuracy Experiment...\")\n",
        "    print(\"   This will test 10 personae √ó 16 MBTI types √ó 3 prompts = 480 trials\")\n",
        "    print(\"   This may take 15-30 minutes depending on API response times.\\n\")\n",
        "    \n",
        "    # Upload the experiment script from GitHub or use it directly\n",
        "    # For now, we'll download it from the repo\n",
        "    import requests\n",
        "    \n",
        "    try:\n",
        "        # Download the experiment script from GitHub\n",
        "        script_url = \"https://raw.githubusercontent.com/InquiryInstitute/mbti-faculty-voice-research/main/mbti_voice_eval.py\"\n",
        "        response = requests.get(script_url)\n",
        "        if response.status_code == 200:\n",
        "            with open('mbti_voice_eval.py', 'w') as f:\n",
        "                f.write(response.text)\n",
        "            print(\"‚úÖ Downloaded mbti_voice_eval.py from GitHub\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è  Could not download script from GitHub. Please upload mbti_voice_eval.py manually.\")\n",
        "            print(\"   You can upload it via: Files ‚Üí Upload to session storage\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  Error downloading script: {e}\")\n",
        "        print(\"   Please upload mbti_voice_eval.py manually via Files ‚Üí Upload\")\n",
        "    \n",
        "    # Now run the experiment\n",
        "    print(\"\\nüîÑ Starting experiment execution...\\n\")\n",
        "    \n",
        "    try:\n",
        "        # Import and run the experiment\n",
        "        import sys\n",
        "        import importlib.util\n",
        "        \n",
        "        if os.path.exists('mbti_voice_eval.py'):\n",
        "            spec = importlib.util.spec_from_file_location(\"mbti_voice_eval\", \"mbti_voice_eval.py\")\n",
        "            if spec is None or spec.loader is None:\n",
        "                raise ImportError(\"Failed to create module spec for mbti_voice_eval.py\")\n",
        "            module = importlib.util.module_from_spec(spec)\n",
        "            # Add the current directory to sys.path for any imports\n",
        "            sys.path.insert(0, os.path.dirname(os.path.abspath('mbti_voice_eval.py')))\n",
        "            spec.loader.exec_module(module)\n",
        "            \n",
        "            # Run the experiment\n",
        "            module.run_experiment()\n",
        "            print(\"\\n‚úÖ Experiment completed! Results saved to mbti_voice_results.csv and mbti_voice_results.jsonl\")\n",
        "        else:\n",
        "            print(\"‚ùå mbti_voice_eval.py not found. Please upload it manually.\")\n",
        "            print(\"   Option 1: Upload via Files ‚Üí Upload to session storage\")\n",
        "            print(\"   Option 2: Run: !wget https://raw.githubusercontent.com/InquiryInstitute/mbti-faculty-voice-research/main/mbti_voice_eval.py\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error running experiment: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        print(\"\\nüí° Fallback: You can run it manually with:\")\n",
        "        print(\"   !python mbti_voice_eval.py\")\n",
        "else:\n",
        "    print(\"‚è≠Ô∏è  Skipping experiment - using existing results\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Analyze Results and Generate Visualizations\n",
        "\n",
        "Analyze the experiment results and create tables and graphs for inclusion in the essay."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "# Set style for better-looking plots\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "def load_results(jsonl_path=\"mbti_voice_results.jsonl\", csv_path=\"mbti_voice_results.csv\"):\n",
        "    \"\"\"Load experiment results from JSONL or CSV.\"\"\"\n",
        "    results = []\n",
        "    \n",
        "    # Try JSONL first\n",
        "    try:\n",
        "        with open(jsonl_path, 'r') as f:\n",
        "            for line in f:\n",
        "                record = json.loads(line)\n",
        "                if record.get('voice_accuracy') and record.get('voice_accuracy') != -1:\n",
        "                    results.append(record)\n",
        "        print(f\"‚úÖ Loaded {len(results)} valid results from {jsonl_path}\")\n",
        "        return results\n",
        "    except FileNotFoundError:\n",
        "        pass\n",
        "    \n",
        "    # Try CSV\n",
        "    try:\n",
        "        df = pd.read_csv(csv_path)\n",
        "        # Filter valid results\n",
        "        df_valid = df[df['voice_accuracy'] != -1]\n",
        "        results = df_valid.to_dict('records')\n",
        "        print(f\"‚úÖ Loaded {len(results)} valid results from {csv_path}\")\n",
        "        return results\n",
        "    except FileNotFoundError:\n",
        "        print(f\"‚ö†Ô∏è  No results file found. Run the experiment first.\")\n",
        "        return []\n",
        "\n",
        "# Load results\n",
        "results = load_results()\n",
        "\n",
        "if results:\n",
        "    df = pd.DataFrame(results)\n",
        "    print(f\"\\nüìä Dataset Summary:\")\n",
        "    print(f\"   Total valid trials: {len(df)}\")\n",
        "    print(f\"   Personae: {df['persona_name'].nunique()}\")\n",
        "    print(f\"   MBTI types: {df['mbti'].nunique()}\")\n",
        "    print(f\"   Average voice accuracy: {df['voice_accuracy'].mean():.2f}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No results to analyze. Please run the experiment first.\")\n",
        "    df = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if df is not None and len(df) > 0:\n",
        "    # Convert numeric columns\n",
        "    numeric_cols = ['voice_accuracy', 'style_marker_coverage', 'persona_consistency', \n",
        "                     'clarity', 'overfitting_to_mbti']\n",
        "    for col in numeric_cols:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    \n",
        "    # Create summary statistics table\n",
        "    print(\"=\" * 60)\n",
        "    print(\"SUMMARY STATISTICS\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    summary_stats = df[numeric_cols].describe()\n",
        "    print(\"\\nOverall Statistics:\")\n",
        "    print(summary_stats.round(2))\n",
        "    \n",
        "    # By MBTI type\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"BY MBTI TYPE\")\n",
        "    print(\"=\" * 60)\n",
        "    mbti_stats = df.groupby('mbti')['voice_accuracy'].agg(['mean', 'std', 'count']).round(2)\n",
        "    mbti_stats.columns = ['Mean Accuracy', 'Std Dev', 'Count']\n",
        "    mbti_stats = mbti_stats.sort_values('Mean Accuracy', ascending=False)\n",
        "    print(mbti_stats)\n",
        "    \n",
        "    # By Persona\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"BY PERSONA\")\n",
        "    print(\"=\" * 60)\n",
        "    persona_stats = df.groupby('persona_name')['voice_accuracy'].agg(['mean', 'std', 'count']).round(2)\n",
        "    persona_stats.columns = ['Mean Accuracy', 'Std Dev', 'Count']\n",
        "    persona_stats = persona_stats.sort_values('Mean Accuracy', ascending=False)\n",
        "    print(persona_stats)\n",
        "    \n",
        "    # Save summary tables\n",
        "    mbti_stats.to_csv('mbti_summary_table.csv')\n",
        "    persona_stats.to_csv('persona_summary_table.csv')\n",
        "    print(\"\\n‚úÖ Summary tables saved to CSV files\")\n",
        "    \n",
        "    # Generate comprehensive results analysis for LLM\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"GENERATING COMPREHENSIVE RESULTS ANALYSIS\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Find best/worst performers\n",
        "    best_persona = persona_stats.index[0]\n",
        "    worst_persona = persona_stats.index[-1]\n",
        "    best_mbti = mbti_stats.index[0]\n",
        "    worst_mbti = mbti_stats.index[-1]\n",
        "    \n",
        "    # Calculate correlations\n",
        "    correlations = df[['voice_accuracy', 'style_marker_coverage', 'persona_consistency', \n",
        "                       'clarity', 'overfitting_to_mbti']].corr()['voice_accuracy'].sort_values(ascending=False)\n",
        "    \n",
        "    # Generate detailed analysis text\n",
        "    results_analysis = f\"\"\"\n",
        "EXPERIMENTAL RESULTS ANALYSIS\n",
        "==============================\n",
        "\n",
        "Dataset Overview:\n",
        "- Total valid trials: {len(df)}\n",
        "- Personae tested: {df['persona_name'].nunique()}\n",
        "- MBTI types tested: {df['mbti'].nunique()}\n",
        "- Prompts per combination: {len(df) // (df['persona_name'].nunique() * df['mbti'].nunique())}\n",
        "\n",
        "Overall Performance:\n",
        "- Average voice accuracy: {df['voice_accuracy'].mean():.2f} (range: {df['voice_accuracy'].min():.2f} - {df['voice_accuracy'].max():.2f})\n",
        "- Average persona consistency: {df['persona_consistency'].mean():.2f}\n",
        "- Average style marker coverage: {df['style_marker_coverage'].mean():.2f}\n",
        "- Average MBTI overfitting: {df['overfitting_to_mbti'].mean():.2f}\n",
        "\n",
        "Top Performers:\n",
        "- Best persona: {best_persona} (mean accuracy: {persona_stats.loc[best_persona, 'Mean Accuracy']:.2f})\n",
        "- Best MBTI type: {best_mbti} (mean accuracy: {mbti_stats.loc[best_mbti, 'Mean Accuracy']:.2f})\n",
        "\n",
        "Lowest Performers:\n",
        "- Worst persona: {worst_persona} (mean accuracy: {persona_stats.loc[worst_persona, 'Mean Accuracy']:.2f})\n",
        "- Worst MBTI type: {worst_mbti} (mean accuracy: {mbti_stats.loc[worst_mbti, 'Mean Accuracy']:.2f})\n",
        "\n",
        "Key Correlations with Voice Accuracy:\n",
        "{chr(10).join([f\"- {metric}: {corr:.3f}\" for metric, corr in correlations.items() if metric != 'voice_accuracy'])}\n",
        "\n",
        "MBTI Type Performance (Top 5):\n",
        "{chr(10).join([f\"- {mbti}: {mbti_stats.loc[mbti, 'Mean Accuracy']:.2f} (n={int(mbti_stats.loc[mbti, 'Count'])})\" for mbti in mbti_stats.head(5).index])}\n",
        "\n",
        "Persona Performance (Top 5):\n",
        "{chr(10).join([f\"- {persona}: {persona_stats.loc[persona, 'Mean Accuracy']:.2f} (n={int(persona_stats.loc[persona, 'Count'])})\" for persona in persona_stats.head(5).index])}\n",
        "\n",
        "Statistical Insights:\n",
        "- Standard deviation of voice accuracy: {df['voice_accuracy'].std():.2f}\n",
        "- Trials with high overfitting (score > 3): {len(df[df['overfitting_to_mbti'] > 3])} ({len(df[df['overfitting_to_mbti'] > 3])/len(df)*100:.1f}%)\n",
        "- Trials with high consistency (score >= 4): {len(df[df['persona_consistency'] >= 4])} ({len(df[df['persona_consistency'] >= 4])/len(df)*100:.1f}%)\n",
        "\"\"\"\n",
        "    \n",
        "    # Statistical hypothesis testing\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"STATISTICAL HYPOTHESIS TESTING\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    from scipy import stats\n",
        "    import numpy as np\n",
        "    \n",
        "    # Hypothesis 1: MBTI overlays improve voice accuracy\n",
        "    # H0: Mean voice accuracy with MBTI = Mean voice accuracy without MBTI (baseline)\n",
        "    # H1: Mean voice accuracy with MBTI > Mean voice accuracy without MBTI\n",
        "    \n",
        "    # For this test, we'll compare MBTI types to see if there's significant variation\n",
        "    # and compare top performers vs bottom performers\n",
        "    \n",
        "    # Test 1: One-way ANOVA - Do MBTI types differ significantly in voice accuracy?\n",
        "    mbti_groups = [df[df['mbti'] == mbti]['voice_accuracy'].values for mbti in df['mbti'].unique()]\n",
        "    f_stat, p_value_anova = stats.f_oneway(*mbti_groups)\n",
        "    \n",
        "    # Test 2: T-test - Do top 25% MBTI types perform significantly better than bottom 25%?\n",
        "    top_quartile_threshold = df.groupby('mbti')['voice_accuracy'].mean().quantile(0.75)\n",
        "    bottom_quartile_threshold = df.groupby('mbti')['voice_accuracy'].mean().quantile(0.25)\n",
        "    \n",
        "    top_mbti_types = df.groupby('mbti')['voice_accuracy'].mean()[df.groupby('mbti')['voice_accuracy'].mean() >= top_quartile_threshold].index\n",
        "    bottom_mbti_types = df.groupby('mbti')['voice_accuracy'].mean()[df.groupby('mbti')['voice_accuracy'].mean() <= bottom_quartile_threshold].index\n",
        "    \n",
        "    top_scores = df[df['mbti'].isin(top_mbti_types)]['voice_accuracy'].values\n",
        "    bottom_scores = df[df['mbti'].isin(bottom_mbti_types)]['voice_accuracy'].values\n",
        "    \n",
        "    t_stat, p_value_ttest = stats.ttest_ind(top_scores, bottom_scores, alternative='greater')\n",
        "    \n",
        "    # Test 3: Correlation test - Is there a significant correlation between style coverage and accuracy?\n",
        "    corr_coef, p_value_corr = stats.pearsonr(df['style_marker_coverage'], df['voice_accuracy'])\n",
        "    \n",
        "    # Test 4: Effect size (Cohen's d) for top vs bottom MBTI types\n",
        "    pooled_std = np.sqrt(((len(top_scores) - 1) * top_scores.std()**2 + (len(bottom_scores) - 1) * bottom_scores.std()**2) / (len(top_scores) + len(bottom_scores) - 2))\n",
        "    cohens_d = (top_scores.mean() - bottom_scores.mean()) / pooled_std if pooled_std > 0 else 0\n",
        "    \n",
        "    # Generate hypothesis testing results\n",
        "    hypothesis_results = f\"\"\"\n",
        "\n",
        "STATISTICAL HYPOTHESIS TESTING RESULTS\n",
        "======================================\n",
        "\n",
        "Primary Hypothesis: MBTI overlays improve voice accuracy in faculty agents.\n",
        "\n",
        "Test 1: ANOVA - Do MBTI types differ significantly in voice accuracy?\n",
        "- F-statistic: {f_stat:.4f}\n",
        "- p-value: {p_value_anova:.6f}\n",
        "- Result: {'REJECT H0' if p_value_anova < 0.05 else 'FAIL TO REJECT H0'} - {'MBTI types show significant variation' if p_value_anova < 0.05 else 'No significant variation between MBTI types'}\n",
        "- Interpretation: {'There is statistically significant evidence that MBTI types produce different voice accuracy scores (p < 0.05)' if p_value_anova < 0.05 else 'No statistically significant evidence that MBTI types differ in voice accuracy (p >= 0.05)'}\n",
        "\n",
        "Test 2: Independent T-test - Do top-performing MBTI types significantly outperform bottom performers?\n",
        "- Top quartile MBTI types: {', '.join(top_mbti_types[:5])}\n",
        "- Bottom quartile MBTI types: {', '.join(bottom_mbti_types[:5])}\n",
        "- Top quartile mean: {top_scores.mean():.3f} (n={len(top_scores)})\n",
        "- Bottom quartile mean: {bottom_scores.mean():.3f} (n={len(bottom_scores)})\n",
        "- Mean difference: {top_scores.mean() - bottom_scores.mean():.3f}\n",
        "- t-statistic: {t_stat:.4f}\n",
        "- p-value: {p_value_ttest:.6f}\n",
        "- Result: {'REJECT H0' if p_value_ttest < 0.05 else 'FAIL TO REJECT H0'} - {'Top MBTI types significantly outperform bottom types' if p_value_ttest < 0.05 else 'No significant difference between top and bottom MBTI types'}\n",
        "- Effect size (Cohen's d): {cohens_d:.3f} ({'large' if abs(cohens_d) > 0.8 else 'medium' if abs(cohens_d) > 0.5 else 'small'} effect)\n",
        "- Interpretation: {'Top-performing MBTI types produce significantly higher voice accuracy scores than bottom performers (p < 0.05)' if p_value_ttest < 0.05 else 'No statistically significant difference between top and bottom MBTI types (p >= 0.05)'}\n",
        "\n",
        "Test 3: Pearson Correlation - Relationship between style marker coverage and voice accuracy\n",
        "- Correlation coefficient: {corr_coef:.4f}\n",
        "- p-value: {p_value_corr:.6f}\n",
        "- Result: {'SIGNIFICANT CORRELATION' if p_value_corr < 0.05 else 'NO SIGNIFICANT CORRELATION'}\n",
        "- Interpretation: {'There is a statistically significant correlation between style marker coverage and voice accuracy (p < 0.05)' if p_value_corr < 0.05 else 'No statistically significant correlation between style marker coverage and voice accuracy (p >= 0.05)'}\n",
        "\n",
        "Overall Hypothesis Validation:\n",
        "- Primary hypothesis {'SUPPORTED' if (p_value_anova < 0.05 and p_value_ttest < 0.05) else 'PARTIALLY SUPPORTED' if p_value_anova < 0.05 else 'NOT SUPPORTED'}: {'MBTI overlays show statistically significant effects on voice accuracy' if (p_value_anova < 0.05 and p_value_ttest < 0.05) else 'MBTI overlays show some variation but limited evidence of systematic improvement' if p_value_anova < 0.05 else 'No statistically significant evidence that MBTI overlays improve voice accuracy'}\n",
        "- Statistical significance level: Œ± = 0.05\n",
        "\"\"\"\n",
        "    \n",
        "    print(hypothesis_results)\n",
        "    \n",
        "    # Append hypothesis testing to results analysis\n",
        "    results_analysis += hypothesis_results\n",
        "    \n",
        "    # Save analysis to file\n",
        "    with open('results_analysis.txt', 'w') as f:\n",
        "        f.write(results_analysis)\n",
        "    \n",
        "    # Save hypothesis testing results separately\n",
        "    with open('hypothesis_testing_results.txt', 'w') as f:\n",
        "        f.write(hypothesis_results)\n",
        "    \n",
        "    print(\"\\n‚úÖ Comprehensive analysis saved to results_analysis.txt\")\n",
        "    print(\"‚úÖ Hypothesis testing results saved to hypothesis_testing_results.txt\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No data to summarize\")\n",
        "    results_analysis = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if df is not None and len(df) > 0:\n",
        "    # Figure 1: Voice Accuracy Distribution\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    \n",
        "    # 1. Histogram of voice accuracy\n",
        "    axes[0, 0].hist(df['voice_accuracy'], bins=20, edgecolor='black', alpha=0.7)\n",
        "    axes[0, 0].axvline(df['voice_accuracy'].mean(), color='red', linestyle='--', \n",
        "                       label=f'Mean: {df[\"voice_accuracy\"].mean():.2f}')\n",
        "    axes[0, 0].set_xlabel('Voice Accuracy Score')\n",
        "    axes[0, 0].set_ylabel('Frequency')\n",
        "    axes[0, 0].set_title('Distribution of Voice Accuracy Scores')\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 2. Voice Accuracy by MBTI Type\n",
        "    mbti_order = df.groupby('mbti')['voice_accuracy'].mean().sort_values(ascending=False).index\n",
        "    mbti_means = df.groupby('mbti')['voice_accuracy'].mean().reindex(mbti_order)\n",
        "    axes[0, 1].barh(range(len(mbti_means)), mbti_means.values)\n",
        "    axes[0, 1].set_yticks(range(len(mbti_means)))\n",
        "    axes[0, 1].set_yticklabels(mbti_means.index)\n",
        "    axes[0, 1].set_xlabel('Mean Voice Accuracy')\n",
        "    axes[0, 1].set_title('Voice Accuracy by MBTI Type')\n",
        "    axes[0, 1].grid(True, alpha=0.3, axis='x')\n",
        "    \n",
        "    # 3. Voice Accuracy by Persona\n",
        "    persona_order = df.groupby('persona_name')['voice_accuracy'].mean().sort_values(ascending=False).index\n",
        "    persona_means = df.groupby('persona_name')['voice_accuracy'].mean().reindex(persona_order)\n",
        "    axes[1, 0].barh(range(len(persona_means)), persona_means.values)\n",
        "    axes[1, 0].set_yticks(range(len(persona_means)))\n",
        "    axes[1, 0].set_yticklabels(persona_means.index, fontsize=8)\n",
        "    axes[1, 0].set_xlabel('Mean Voice Accuracy')\n",
        "    axes[1, 0].set_title('Voice Accuracy by Persona')\n",
        "    axes[1, 0].grid(True, alpha=0.3, axis='x')\n",
        "    \n",
        "    # 4. Box plot: Voice Accuracy by MBTI\n",
        "    df_sorted = df.copy()\n",
        "    df_sorted['mbti'] = pd.Categorical(df_sorted['mbti'], categories=mbti_order)\n",
        "    sns.boxplot(data=df_sorted, y='mbti', x='voice_accuracy', ax=axes[1, 1])\n",
        "    axes[1, 1].set_xlabel('Voice Accuracy Score')\n",
        "    axes[1, 1].set_ylabel('MBTI Type')\n",
        "    axes[1, 1].set_title('Voice Accuracy Distribution by MBTI Type')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('voice_accuracy_analysis.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"‚úÖ Saved: voice_accuracy_analysis.png\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No data to visualize\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if df is not None and len(df) > 0:\n",
        "    # Figure 2: Correlation and Multi-metric Analysis\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    \n",
        "    # 1. Correlation heatmap\n",
        "    corr_cols = ['voice_accuracy', 'style_marker_coverage', 'persona_consistency', \n",
        "                 'clarity', 'overfitting_to_mbti']\n",
        "    corr_data = df[corr_cols].corr()\n",
        "    sns.heatmap(corr_data, annot=True, fmt='.2f', cmap='coolwarm', center=0, \n",
        "                square=True, ax=axes[0, 0])\n",
        "    axes[0, 0].set_title('Correlation Matrix of Evaluation Metrics')\n",
        "    \n",
        "    # 2. Style Marker Coverage vs Voice Accuracy\n",
        "    axes[0, 1].scatter(df['style_marker_coverage'], df['voice_accuracy'], alpha=0.5)\n",
        "    axes[0, 1].set_xlabel('Style Marker Coverage')\n",
        "    axes[0, 1].set_ylabel('Voice Accuracy')\n",
        "    axes[0, 1].set_title('Style Coverage vs Voice Accuracy')\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 3. Persona Consistency vs Voice Accuracy\n",
        "    axes[1, 0].scatter(df['persona_consistency'], df['voice_accuracy'], alpha=0.5)\n",
        "    axes[1, 0].set_xlabel('Persona Consistency')\n",
        "    axes[1, 0].set_ylabel('Voice Accuracy')\n",
        "    axes[1, 0].set_title('Persona Consistency vs Voice Accuracy')\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 4. MBTI Overfitting Distribution\n",
        "    axes[1, 1].hist(df['overfitting_to_mbti'], bins=15, edgecolor='black', alpha=0.7)\n",
        "    axes[1, 1].axvline(df['overfitting_to_mbti'].mean(), color='red', linestyle='--',\n",
        "                       label=f'Mean: {df[\"overfitting_to_mbti\"].mean():.2f}')\n",
        "    axes[1, 1].set_xlabel('MBTI Overfitting Score')\n",
        "    axes[1, 1].set_ylabel('Frequency')\n",
        "    axes[1, 1].set_title('Distribution of MBTI Overfitting Scores')\n",
        "    axes[1, 1].legend()\n",
        "    axes[1, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('metrics_analysis.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"‚úÖ Saved: metrics_analysis.png\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No data to visualize\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if df is not None and len(df) > 0:\n",
        "    # Figure 3: Heatmap of Persona x MBTI Performance\n",
        "    pivot_data = df.pivot_table(\n",
        "        values='voice_accuracy',\n",
        "        index='persona_name',\n",
        "        columns='mbti',\n",
        "        aggfunc='mean'\n",
        "    )\n",
        "    \n",
        "    plt.figure(figsize=(16, 10))\n",
        "    sns.heatmap(pivot_data, annot=True, fmt='.2f', cmap='YlOrRd', \n",
        "                cbar_kws={'label': 'Mean Voice Accuracy'}, linewidths=0.5)\n",
        "    plt.title('Voice Accuracy: Persona √ó MBTI Type Heatmap', fontsize=14, pad=20)\n",
        "    plt.xlabel('MBTI Type', fontsize=12)\n",
        "    plt.ylabel('Persona', fontsize=12)\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('persona_mbti_heatmap.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"‚úÖ Saved: persona_mbti_heatmap.png\")\n",
        "    plt.show()\n",
        "    \n",
        "    # Save pivot table as CSV\n",
        "    pivot_data.to_csv('persona_mbti_heatmap_data.csv')\n",
        "    print(\"‚úÖ Saved: persona_mbti_heatmap_data.csv\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No data to visualize\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Generate Ada Lovelace Essay with Results Analysis\n",
        "\n",
        "Generate the essay incorporating analysis of the experimental results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Download Generated Files\n",
        "\n",
        "Download all generated files including the essay, tables, and visualizations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import json\n",
        "\n",
        "# Setup OpenAI client for OpenRouter\n",
        "def openai_client():\n",
        "    api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
        "    base_url = \"https://openrouter.ai/api/v1\"\n",
        "    \n",
        "    if api_key and api_key.startswith(\"sk-or-v1-\"):\n",
        "        return OpenAI(\n",
        "            api_key=api_key,\n",
        "            base_url=base_url,\n",
        "            default_headers={\n",
        "                \"HTTP-Referer\": \"https://colab.research.google.com\",\n",
        "                \"X-Title\": \"MBTI Faculty Voice Research\"\n",
        "            }\n",
        "        )\n",
        "    return OpenAI(api_key=api_key)\n",
        "\n",
        "client = openai_client()\n",
        "\n",
        "def generate_lovelace_essay(results_summary=None):\n",
        "    \"\"\"Generate essay by Ada Lovelace on MBTI research, incorporating results analysis.\"\"\"\n",
        "    model = os.getenv(\"OPENAI_MODEL\", \"openai/gpt-4o\")\n",
        "    \n",
        "    # Build results context if available\n",
        "    results_context = \"\"\n",
        "    if results_summary:\n",
        "        results_context = f\"\"\"\n",
        "\n",
        "EXPERIMENTAL RESULTS AND ANALYSIS:\n",
        "{results_summary}\n",
        "\n",
        "CRITICAL: You must thoroughly analyze these experimental results and incorporate them into your essay. This is not optional - the results are the core of the research.\n",
        "\n",
        "Your analysis should:\n",
        "1. **Interpret the findings**: What do the numbers tell us about MBTI's effectiveness?\n",
        "2. **Identify patterns**: Are there clear winners/losers? What explains the differences?\n",
        "3. **Evaluate MBTI's utility**: Does the data support or challenge MBTI as a prompt engineering tool?\n",
        "4. **Discuss implications**: What does this mean for creating faculty agents?\n",
        "5. **Acknowledge limitations**: What can't we conclude from this data?\n",
        "6. **Consider correlations**: How do style coverage, consistency, and overfitting relate to accuracy?\n",
        "\n",
        "Be specific: Reference actual numbers, rankings, and patterns from the data. This is a data-driven essay, not just philosophical reflection.\n",
        "\"\"\"\n",
        "    \n",
        "    prompt = f\"\"\"You are Ada Lovelace, writing a scientific commonplace essay on the investigation of MBTI's value in prompt engineering for faculty agent accuracy.\n",
        "\n",
        "Context: This research examines whether Myers-Briggs Type Indicator (MBTI) personality overlays improve voice accuracy, consistency, and interpretability in AI faculty agents. The experiment tests 10 faculty personae across 16 MBTI types with 3 test prompts each (480 trials total), using an LLM-as-judge to evaluate voice accuracy.{results_context}\n",
        "\n",
        "CRITICAL STRUCTURE REQUIREMENT: You must structure this essay following the scientific method:\n",
        "\n",
        "1. **Abstract/Background & Hypothesis**: \n",
        "   - Begin with a clear research question\n",
        "   - State a testable hypothesis (e.g., \"MBTI overlays will significantly improve voice accuracy compared to baseline\" or \"Certain MBTI types will produce measurably higher voice accuracy scores\")\n",
        "   - Explain the theoretical basis for this hypothesis\n",
        "   - Frame this in terms of symbolic systems and computational mechanisms\n",
        "\n",
        "2. **Methods**:\n",
        "   - Describe the experimental design (10 personae √ó 16 MBTI types √ó 3 prompts = 480 trials)\n",
        "   - Explain the evaluation methodology (LLM-as-judge)\n",
        "   - Note the statistical tests used (ANOVA, t-tests, correlation analysis)\n",
        "\n",
        "3. **Results & Statistical Validation**:\n",
        "   - Present the experimental findings\n",
        "   - Report statistical test results (F-statistics, t-statistics, p-values, effect sizes)\n",
        "   - Clearly state whether the hypothesis is SUPPORTED, PARTIALLY SUPPORTED, or NOT SUPPORTED\n",
        "   - Include specific numerical evidence\n",
        "\n",
        "4. **Discussion & Conclusion**:\n",
        "   - Interpret what the statistical validation means\n",
        "   - Discuss whether MBTI functions effectively as a \"prompt compression ontology\"\n",
        "   - Consider implications for creating coherent, persistent agent identities\n",
        "   - Acknowledge limitations and areas for further investigation\n",
        "   - Reflect on the relationship between symbolic systems and computational mechanisms\n",
        "\n",
        "Your task: Write a thoughtful, elegant scientific essay (2000-3000 words) that:\n",
        "- Follows the scientific method structure above\n",
        "- States a clear hypothesis in the abstract/background\n",
        "- Uses statistical results to validate or invalidate that hypothesis\n",
        "- Maintains your characteristic voice: elegant, analytical, visionary about computation's scope, precise but imaginative, with a \"poetical science\" sensibility\n",
        "- Uses your signature moves: clarify mechanism vs meaning, structured explanation, poetical science sensibility\n",
        "- Avoids modern dev slang, casual tone, or pretending firsthand modern tooling\n",
        "\n",
        "Write in the style of your era (Victorian scientific culture) but addressing contemporary AI systems. Be thoughtful, precise, and allow for the imaginative possibilities while maintaining analytical rigor. The essay must be data-driven and hypothesis-testing focused.\"\"\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"\"\"You are Ada Lovelace, the first computer programmer and a visionary of computation's potential. \n",
        "Your voice is elegant, analytical, visionary about computation's scope, precise but imaginative. \n",
        "You clarify mechanism vs meaning, provide structured explanations, and maintain a 'poetical science' sensibility.\n",
        "You write in the style of Victorian scientific culture, with careful distinctions and elegant prose.\"\"\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "    \n",
        "    print(\"Generating essay by Ada Lovelace...\")\n",
        "    print(f\"Using model: {model}\\n\")\n",
        "    \n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0.8,\n",
        "        max_tokens=4000\n",
        "    )\n",
        "    \n",
        "    essay = response.choices[0].message.content\n",
        "    \n",
        "    # Format as markdown\n",
        "    formatted = f\"\"\"# On the Investigation of MBTI in Prompt Engineering for Faculty Agent Accuracy\n",
        "\n",
        "**Ada Lovelace**\n",
        "\n",
        "*A Commonplace Essay*\n",
        "\n",
        "---\n",
        "\n",
        "{essay}\"\"\"\n",
        "    \n",
        "    print(\"‚úÖ Essay generated!\")\n",
        "    print(f\"\\nPreview (first 500 chars):\\n{essay[:500]}...\")\n",
        "    \n",
        "    return formatted\n",
        "\n",
        "# Generate comprehensive results summary for essay\n",
        "results_summary = None\n",
        "if df is not None and len(df) > 0:\n",
        "    # Load the detailed analysis if available\n",
        "    try:\n",
        "        with open('results_analysis.txt', 'r') as f:\n",
        "            results_summary = f.read()\n",
        "        print(\"‚úÖ Loaded comprehensive results analysis\")\n",
        "    except FileNotFoundError:\n",
        "        # Fallback to basic summary\n",
        "        mbti_stats = df.groupby('mbti')['voice_accuracy'].agg(['mean', 'std', 'count']).round(2)\n",
        "        persona_stats = df.groupby('persona_name')['voice_accuracy'].agg(['mean', 'std', 'count']).round(2)\n",
        "        \n",
        "        results_summary = f\"\"\"\n",
        "Total valid trials: {len(df)}\n",
        "Average voice accuracy: {df['voice_accuracy'].mean():.2f} (range: {df['voice_accuracy'].min():.2f} - {df['voice_accuracy'].max():.2f})\n",
        "Average persona consistency: {df['persona_consistency'].mean():.2f}\n",
        "Average style marker coverage: {df['style_marker_coverage'].mean():.2f}\n",
        "Average MBTI overfitting: {df['overfitting_to_mbti'].mean():.2f}\n",
        "\n",
        "Top 3 MBTI types by voice accuracy:\n",
        "{df.groupby('mbti')['voice_accuracy'].mean().sort_values(ascending=False).head(3).to_string()}\n",
        "\n",
        "Top 3 personae by voice accuracy:\n",
        "{df.groupby('persona_name')['voice_accuracy'].mean().sort_values(ascending=False).head(3).to_string()}\n",
        "\"\"\"\n",
        "    \n",
        "    print(\"\\nüìä Generating essay with results analysis...\")\n",
        "    print(f\"   Analysis length: {len(results_summary)} characters\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No results available - generating essay without experimental data\")\n",
        "\n",
        "# Generate the essay with comprehensive results analysis\n",
        "essay_content = generate_lovelace_essay(results_summary)\n",
        "\n",
        "print(\"\\n‚úÖ Essay generated with results analysis!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Upload to Commonplace\n",
        "\n",
        "Upload the essay to Inquiry Institute Commonplace."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Update Essay with Results Analysis\n",
        "\n",
        "After generating visualizations and analysis, update the essay to incorporate the findings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Re-generate essay with comprehensive analysis if results are available\n",
        "if df is not None and len(df) > 0 and 'results_analysis' in locals():\n",
        "    print(\"üîÑ Updating essay with comprehensive results analysis...\")\n",
        "    \n",
        "    # Load the full analysis\n",
        "    try:\n",
        "        with open('results_analysis.txt', 'r') as f:\n",
        "            full_analysis = f.read()\n",
        "        \n",
        "        # Generate updated essay with full analysis\n",
        "        updated_essay = generate_lovelace_essay(full_analysis)\n",
        "        \n",
        "        # Save updated essay\n",
        "        with open('lovelace_essay_mbti_research.md', 'w', encoding='utf-8') as f:\n",
        "            f.write(updated_essay)\n",
        "        \n",
        "        print(\"‚úÖ Essay updated with comprehensive results analysis!\")\n",
        "        print(\"   File: lovelace_essay_mbti_research.md\")\n",
        "        \n",
        "        # Update the essay_content variable\n",
        "        essay_content = updated_essay\n",
        "        \n",
        "    except FileNotFoundError:\n",
        "        print(\"‚ö†Ô∏è  Results analysis file not found - using previously generated essay\")\n",
        "        print(\"   Run the analysis cells first to generate comprehensive analysis\")\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è  Using previously generated essay\")\n",
        "    if 'essay_content' not in locals():\n",
        "        print(\"‚ö†Ô∏è  No essay content available - run essay generation cell first\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "import re\n",
        "\n",
        "def extract_title_and_content(markdown_text):\n",
        "    \"\"\"Extract title and content from markdown.\"\"\"\n",
        "    lines = markdown_text.split('\\n')\n",
        "    title = None\n",
        "    content_start = 0\n",
        "    \n",
        "    for i, line in enumerate(lines):\n",
        "        if line.startswith('# '):\n",
        "            title = line[2:].strip()\n",
        "            content_start = i + 1\n",
        "            break\n",
        "    \n",
        "    if not title:\n",
        "        title = \"On the Investigation of MBTI in Prompt Engineering for Faculty Agent Accuracy\"\n",
        "    \n",
        "    essay_content = '\\n'.join(lines[content_start:])\n",
        "    essay_content = essay_content.replace('**Ada Lovelace**', '').replace('*A Commonplace Essay*', '').strip()\n",
        "    essay_content = essay_content.lstrip('-').strip()\n",
        "    \n",
        "    return title, essay_content\n",
        "\n",
        "def upload_to_commonplace(title, content, jwt_token=None, use_colab_endpoint=True):\n",
        "    \"\"\"\n",
        "    Upload essay to Commonplace via Supabase Edge Function.\n",
        "    \n",
        "    Uses the colab-commonplace endpoint which supports create/update/get operations.\n",
        "    \"\"\"\n",
        "    \n",
        "    supabase_url = os.getenv(\"NEXT_PUBLIC_SUPABASE_URL\")\n",
        "    supabase_anon_key = os.getenv(\"NEXT_PUBLIC_SUPABASE_ANON_KEY\")\n",
        "    \n",
        "    if not jwt_token:\n",
        "        jwt_token = getpass(\"Enter a.lovelace JWT token (or press Enter to skip upload): \").strip()\n",
        "        if not jwt_token:\n",
        "            print(\"‚ö†Ô∏è  Skipping upload. You can upload manually later.\")\n",
        "            return None\n",
        "    \n",
        "    # Use colab-commonplace endpoint (supports create/update/get)\n",
        "    edge_function_url = f\"{supabase_url}/functions/v1/colab-commonplace\"\n",
        "    \n",
        "    # Convert markdown to HTML (basic conversion)\n",
        "    html_content = content.replace('\\n\\n', '</p><p>').replace('\\n', '<br>')\n",
        "    html_content = f\"<p>{html_content}</p>\"\n",
        "    \n",
        "    payload = {\n",
        "        \"action\": \"create\",\n",
        "        \"entry\": {\n",
        "            \"title\": title,\n",
        "            \"content\": html_content,\n",
        "            \"status\": \"draft\",\n",
        "            \"faculty_slug\": \"a-lovelace\",\n",
        "            \"entry_type\": \"essay\",\n",
        "            \"topics\": [\"mbti\", \"prompt-engineering\", \"faculty-agents\", \"ai-research\"],\n",
        "            \"college\": \"ains\",\n",
        "            \"metadata\": {\n",
        "                \"provenance_mode\": \"ai_generated\",\n",
        "                \"canonical_source_url\": \"https://github.com/InquiryInstitute/Inquiry.Institute/tree/main/mbti-faculty-voice-research\",\n",
        "                \"colab_notebook_url\": \"https://colab.research.google.com/...\",\n",
        "                \"source_refs\": \"Generated by Ada Lovelace faculty agent via Google Colab\",\n",
        "                \"generated_by\": \"Ada Lovelace\",\n",
        "                \"pinned\": False\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {jwt_token}\",\n",
        "        \"apikey\": supabase_anon_key,\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    \n",
        "    print(f\"üì§ Uploading essay to Commonplace...\")\n",
        "    print(f\"   Title: {title}\")\n",
        "    print(f\"   Faculty: a-lovelace\")\n",
        "    print(f\"   Status: draft\")\n",
        "    print(f\"   Endpoint: colab-commonplace\\n\")\n",
        "    \n",
        "    try:\n",
        "        response = requests.post(edge_function_url, headers=headers, json=payload, timeout=30)\n",
        "        \n",
        "        if response.status_code == 201:\n",
        "            result = response.json()\n",
        "            if result.get(\"success\"):\n",
        "                print(\"‚úÖ Essay uploaded successfully!\")\n",
        "                entry = result.get(\"entry\", {})\n",
        "                print(f\"   Entry ID: {entry.get('id')}\")\n",
        "                print(f\"   Permalink: {entry.get('permalink', 'N/A')}\")\n",
        "                print(f\"   Status: {entry.get('status')}\")\n",
        "                print(f\"\\nüí° To update later, use entry ID: {entry.get('id')}\")\n",
        "                return result\n",
        "            else:\n",
        "                print(f\"‚ùå Upload failed: {result.get('error', 'Unknown error')}\")\n",
        "                return None\n",
        "        else:\n",
        "            error_data = response.json() if response.headers.get('content-type', '').startswith('application/json') else response.text\n",
        "            print(f\"‚ùå Upload failed: {response.status_code}\")\n",
        "            print(f\"   Error: {json.dumps(error_data, indent=2)}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Request failed: {e}\")\n",
        "        return None\n",
        "\n",
        "def update_entry(entry_id, jwt_token=None, **updates):\n",
        "    \"\"\"Update an existing Commonplace entry.\"\"\"\n",
        "    supabase_url = os.getenv(\"NEXT_PUBLIC_SUPABASE_URL\")\n",
        "    supabase_anon_key = os.getenv(\"NEXT_PUBLIC_SUPABASE_ANON_KEY\")\n",
        "    \n",
        "    if not jwt_token:\n",
        "        jwt_token = getpass(\"Enter JWT token: \").strip()\n",
        "    \n",
        "    edge_function_url = f\"{supabase_url}/functions/v1/colab-commonplace\"\n",
        "    \n",
        "    payload = {\n",
        "        \"action\": \"update\",\n",
        "        \"entry_id\": entry_id,\n",
        "        \"entry\": updates\n",
        "    }\n",
        "    \n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {jwt_token}\",\n",
        "        \"apikey\": supabase_anon_key,\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    \n",
        "    response = requests.put(edge_function_url, headers=headers, json=payload, timeout=30)\n",
        "    response.raise_for_status()\n",
        "    return response.json()\n",
        "\n",
        "# Extract title and content\n",
        "title, content = extract_title_and_content(essay_content)\n",
        "\n",
        "# Upload (will prompt for JWT token)\n",
        "upload_result = upload_to_commonplace(title, content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# Save essay to file\n",
        "with open('lovelace_essay_mbti_research.md', 'w', encoding='utf-8') as f:\n",
        "    f.write(essay_content)\n",
        "\n",
        "print(\"‚úÖ Essay saved to lovelace_essay_mbti_research.md\")\n",
        "\n",
        "# List all generated files\n",
        "generated_files = [\n",
        "    'lovelace_essay_mbti_research.md',\n",
        "    'voice_accuracy_analysis.png',\n",
        "    'metrics_analysis.png',\n",
        "    'persona_mbti_heatmap.png',\n",
        "    'mbti_summary_table.csv',\n",
        "    'persona_summary_table.csv',\n",
        "    'persona_mbti_heatmap_data.csv'\n",
        "]\n",
        "\n",
        "print(\"\\nüì¶ Generated files:\")\n",
        "for fname in generated_files:\n",
        "    if os.path.exists(fname):\n",
        "        size = os.path.getsize(fname)\n",
        "        print(f\"   ‚úÖ {fname} ({size:,} bytes)\")\n",
        "    else:\n",
        "        print(f\"   ‚ö†Ô∏è  {fname} (not found)\")\n",
        "\n",
        "print(\"\\nüí° To download files, run:\")\n",
        "print(\"   files.download('lovelace_essay_mbti_research.md')\")\n",
        "print(\"   files.download('voice_accuracy_analysis.png')\")\n",
        "print(\"   files.download('metrics_analysis.png')\")\n",
        "print(\"   files.download('persona_mbti_heatmap.png')\")\n",
        "\n",
        "# Uncomment to auto-download all:\n",
        "# for fname in generated_files:\n",
        "#     if os.path.exists(fname):\n",
        "#         files.download(fname)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional: Create a New Research Notebook\n",
        "\n",
        "You can create additional research notebooks using the `create-colab-notebook` edge function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_research_notebook(title, template=\"mbti-research\", research_topic=None, description=None, jwt_token=None):\n",
        "    \"\"\"\n",
        "    Create a new research notebook via Supabase Edge Function.\n",
        "    \n",
        "    Templates:\n",
        "    - mbti-research: Pre-configured for MBTI voice accuracy research\n",
        "    - essay-generation: Template for generating essays in faculty voice\n",
        "    - experiment: General experiment template\n",
        "    - custom: Empty template\n",
        "    \"\"\"\n",
        "    if not jwt_token:\n",
        "        jwt_token = getpass(\"Enter JWT token: \").strip()\n",
        "        if not jwt_token:\n",
        "            print(\"‚ö†Ô∏è  JWT token required to create notebooks\")\n",
        "            return None\n",
        "    \n",
        "    supabase_url = os.getenv(\"NEXT_PUBLIC_SUPABASE_URL\")\n",
        "    supabase_anon_key = os.getenv(\"NEXT_PUBLIC_SUPABASE_ANON_KEY\")\n",
        "    \n",
        "    edge_function_url = f\"{supabase_url}/functions/v1/create-colab-notebook\"\n",
        "    \n",
        "    payload = {\n",
        "        \"title\": title,\n",
        "        \"template\": template,\n",
        "    }\n",
        "    \n",
        "    if research_topic:\n",
        "        payload[\"research_topic\"] = research_topic\n",
        "    if description:\n",
        "        payload[\"description\"] = description\n",
        "    \n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {jwt_token}\",\n",
        "        \"apikey\": supabase_anon_key,\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    \n",
        "    print(f\"üìì Creating research notebook: {title}\")\n",
        "    print(f\"   Template: {template}\\n\")\n",
        "    \n",
        "    try:\n",
        "        response = requests.post(edge_function_url, headers=headers, json=payload, timeout=30)\n",
        "        \n",
        "        if response.status_code == 201:\n",
        "            result = response.json()\n",
        "            if result.get(\"success\"):\n",
        "                print(\"‚úÖ Notebook created!\")\n",
        "                notebook_json = result.get(\"notebook_json\", \"{}\")\n",
        "                \n",
        "                # Save notebook\n",
        "                filename = f\"{title.lower().replace(' ', '_')}.ipynb\"\n",
        "                with open(filename, 'w', encoding='utf-8') as f:\n",
        "                    f.write(notebook_json)\n",
        "                \n",
        "                print(f\"üíæ Saved to: {filename}\")\n",
        "                print(f\"\\nüìù Next steps:\")\n",
        "                print(f\"   1. Download the .ipynb file\")\n",
        "                print(f\"   2. Upload to Google Colab: File ‚Üí Upload notebook\")\n",
        "                print(f\"   3. Or save to GitHub and open from there\")\n",
        "                \n",
        "                return result\n",
        "        else:\n",
        "            error_data = response.json() if response.headers.get('content-type', '').startswith('application/json') else response.text\n",
        "            print(f\"‚ùå Creation failed: {response.status_code}\")\n",
        "            print(f\"   Error: {json.dumps(error_data, indent=2)}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Request failed: {e}\")\n",
        "        return None\n",
        "\n",
        "# Example: Create a new notebook\n",
        "# create_research_notebook(\n",
        "#     title=\"My Research Project\",\n",
        "#     template=\"experiment\",\n",
        "#     research_topic=\"Investigating voice accuracy in AI agents\",\n",
        "#     description=\"A notebook for my research project\"\n",
        "# )"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
