{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MBTI Faculty Voice Research - Google Colab\n",
        "\n",
        "This notebook contains:\n",
        "1. **MBTI Voice Accuracy Experiment** - Run the full 480-trial experiment\n",
        "2. **Ada Lovelace Essay Generation** - Generate essay on MBTI research\n",
        "3. **Upload to Commonplace** - Upload essay to Inquiry Institute Commonplace\n",
        "\n",
        "## Setup\n",
        "\n",
        "1. Install dependencies\n",
        "2. Set API keys (OpenRouter, Supabase)\n",
        "3. Run the cells below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q openai pydantic python-dotenv requests pandas matplotlib seaborn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configure API Keys\n",
        "\n",
        "Set your API keys below. For security, you can use Colab's secrets manager or set them directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# OpenRouter API Key (required for experiment and essay generation)\n",
        "OPENROUTER_API_KEY = getpass(\"Enter OpenRouter API Key (sk-or-v1-...): \")\n",
        "os.environ[\"OPENROUTER_API_KEY\"] = OPENROUTER_API_KEY\n",
        "\n",
        "# Supabase credentials (required for uploading to Commonplace)\n",
        "SUPABASE_URL = input(\"Enter Supabase URL (https://xxx.supabase.co): \").strip() or \"https://xougqdomkoisrxdnagcj.supabase.co\"\n",
        "os.environ[\"NEXT_PUBLIC_SUPABASE_URL\"] = SUPABASE_URL\n",
        "\n",
        "SUPABASE_ANON_KEY = getpass(\"Enter Supabase Anon Key: \")\n",
        "os.environ[\"NEXT_PUBLIC_SUPABASE_ANON_KEY\"] = SUPABASE_ANON_KEY\n",
        "\n",
        "print(\"\\n‚úÖ API keys configured!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Run MBTI Voice Accuracy Experiment\n",
        "\n",
        "Run the full experiment or load existing results. The experiment tests 10 faculty personae across 16 MBTI types with 3 test prompts each (480 trials total)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Option 1: Load existing results (if available)\n",
        "# Uncomment to use existing results instead of running the experiment\n",
        "# import json\n",
        "# import csv\n",
        "# \n",
        "# results_file = \"mbti_voice_results.jsonl\"  # or \"mbti_voice_results.csv\"\n",
        "# print(f\"Loading results from {results_file}...\")\n",
        "\n",
        "# Option 2: Run the experiment\n",
        "# Import the experiment script\n",
        "# You can either:\n",
        "# - Upload mbti_voice_eval.py to Colab\n",
        "# - Or copy the experiment code here\n",
        "\n",
        "print(\"üìä To run the experiment:\")\n",
        "print(\"   1. Upload mbti_voice_eval.py to this Colab session\")\n",
        "print(\"   2. Or run: !python mbti_voice_eval.py\")\n",
        "print(\"\\nüí° For now, we'll analyze existing results if available...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Analyze Results and Generate Visualizations\n",
        "\n",
        "Analyze the experiment results and create tables and graphs for inclusion in the essay."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "# Set style for better-looking plots\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "def load_results(jsonl_path=\"mbti_voice_results.jsonl\", csv_path=\"mbti_voice_results.csv\"):\n",
        "    \"\"\"Load experiment results from JSONL or CSV.\"\"\"\n",
        "    results = []\n",
        "    \n",
        "    # Try JSONL first\n",
        "    try:\n",
        "        with open(jsonl_path, 'r') as f:\n",
        "            for line in f:\n",
        "                record = json.loads(line)\n",
        "                if record.get('voice_accuracy') and record.get('voice_accuracy') != -1:\n",
        "                    results.append(record)\n",
        "        print(f\"‚úÖ Loaded {len(results)} valid results from {jsonl_path}\")\n",
        "        return results\n",
        "    except FileNotFoundError:\n",
        "        pass\n",
        "    \n",
        "    # Try CSV\n",
        "    try:\n",
        "        df = pd.read_csv(csv_path)\n",
        "        # Filter valid results\n",
        "        df_valid = df[df['voice_accuracy'] != -1]\n",
        "        results = df_valid.to_dict('records')\n",
        "        print(f\"‚úÖ Loaded {len(results)} valid results from {csv_path}\")\n",
        "        return results\n",
        "    except FileNotFoundError:\n",
        "        print(f\"‚ö†Ô∏è  No results file found. Run the experiment first.\")\n",
        "        return []\n",
        "\n",
        "# Load results\n",
        "results = load_results()\n",
        "\n",
        "if results:\n",
        "    df = pd.DataFrame(results)\n",
        "    print(f\"\\nüìä Dataset Summary:\")\n",
        "    print(f\"   Total valid trials: {len(df)}\")\n",
        "    print(f\"   Personae: {df['persona_name'].nunique()}\")\n",
        "    print(f\"   MBTI types: {df['mbti'].nunique()}\")\n",
        "    print(f\"   Average voice accuracy: {df['voice_accuracy'].mean():.2f}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No results to analyze. Please run the experiment first.\")\n",
        "    df = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if df is not None and len(df) > 0:\n",
        "    # Convert numeric columns\n",
        "    numeric_cols = ['voice_accuracy', 'style_marker_coverage', 'persona_consistency', \n",
        "                     'clarity', 'overfitting_to_mbti']\n",
        "    for col in numeric_cols:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    \n",
        "    # Create summary statistics table\n",
        "    print(\"=\" * 60)\n",
        "    print(\"SUMMARY STATISTICS\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    summary_stats = df[numeric_cols].describe()\n",
        "    print(\"\\nOverall Statistics:\")\n",
        "    print(summary_stats.round(2))\n",
        "    \n",
        "    # By MBTI type\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"BY MBTI TYPE\")\n",
        "    print(\"=\" * 60)\n",
        "    mbti_stats = df.groupby('mbti')['voice_accuracy'].agg(['mean', 'std', 'count']).round(2)\n",
        "    mbti_stats.columns = ['Mean Accuracy', 'Std Dev', 'Count']\n",
        "    mbti_stats = mbti_stats.sort_values('Mean Accuracy', ascending=False)\n",
        "    print(mbti_stats)\n",
        "    \n",
        "    # By Persona\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"BY PERSONA\")\n",
        "    print(\"=\" * 60)\n",
        "    persona_stats = df.groupby('persona_name')['voice_accuracy'].agg(['mean', 'std', 'count']).round(2)\n",
        "    persona_stats.columns = ['Mean Accuracy', 'Std Dev', 'Count']\n",
        "    persona_stats = persona_stats.sort_values('Mean Accuracy', ascending=False)\n",
        "    print(persona_stats)\n",
        "    \n",
        "    # Save summary tables\n",
        "    mbti_stats.to_csv('mbti_summary_table.csv')\n",
        "    persona_stats.to_csv('persona_summary_table.csv')\n",
        "    print(\"\\n‚úÖ Summary tables saved to CSV files\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No data to summarize\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if df is not None and len(df) > 0:\n",
        "    # Figure 1: Voice Accuracy Distribution\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    \n",
        "    # 1. Histogram of voice accuracy\n",
        "    axes[0, 0].hist(df['voice_accuracy'], bins=20, edgecolor='black', alpha=0.7)\n",
        "    axes[0, 0].axvline(df['voice_accuracy'].mean(), color='red', linestyle='--', \n",
        "                       label=f'Mean: {df[\"voice_accuracy\"].mean():.2f}')\n",
        "    axes[0, 0].set_xlabel('Voice Accuracy Score')\n",
        "    axes[0, 0].set_ylabel('Frequency')\n",
        "    axes[0, 0].set_title('Distribution of Voice Accuracy Scores')\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 2. Voice Accuracy by MBTI Type\n",
        "    mbti_order = df.groupby('mbti')['voice_accuracy'].mean().sort_values(ascending=False).index\n",
        "    mbti_means = df.groupby('mbti')['voice_accuracy'].mean().reindex(mbti_order)\n",
        "    axes[0, 1].barh(range(len(mbti_means)), mbti_means.values)\n",
        "    axes[0, 1].set_yticks(range(len(mbti_means)))\n",
        "    axes[0, 1].set_yticklabels(mbti_means.index)\n",
        "    axes[0, 1].set_xlabel('Mean Voice Accuracy')\n",
        "    axes[0, 1].set_title('Voice Accuracy by MBTI Type')\n",
        "    axes[0, 1].grid(True, alpha=0.3, axis='x')\n",
        "    \n",
        "    # 3. Voice Accuracy by Persona\n",
        "    persona_order = df.groupby('persona_name')['voice_accuracy'].mean().sort_values(ascending=False).index\n",
        "    persona_means = df.groupby('persona_name')['voice_accuracy'].mean().reindex(persona_order)\n",
        "    axes[1, 0].barh(range(len(persona_means)), persona_means.values)\n",
        "    axes[1, 0].set_yticks(range(len(persona_means)))\n",
        "    axes[1, 0].set_yticklabels(persona_means.index, fontsize=8)\n",
        "    axes[1, 0].set_xlabel('Mean Voice Accuracy')\n",
        "    axes[1, 0].set_title('Voice Accuracy by Persona')\n",
        "    axes[1, 0].grid(True, alpha=0.3, axis='x')\n",
        "    \n",
        "    # 4. Box plot: Voice Accuracy by MBTI\n",
        "    df_sorted = df.copy()\n",
        "    df_sorted['mbti'] = pd.Categorical(df_sorted['mbti'], categories=mbti_order)\n",
        "    sns.boxplot(data=df_sorted, y='mbti', x='voice_accuracy', ax=axes[1, 1])\n",
        "    axes[1, 1].set_xlabel('Voice Accuracy Score')\n",
        "    axes[1, 1].set_ylabel('MBTI Type')\n",
        "    axes[1, 1].set_title('Voice Accuracy Distribution by MBTI Type')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('voice_accuracy_analysis.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"‚úÖ Saved: voice_accuracy_analysis.png\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No data to visualize\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if df is not None and len(df) > 0:\n",
        "    # Figure 2: Correlation and Multi-metric Analysis\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    \n",
        "    # 1. Correlation heatmap\n",
        "    corr_cols = ['voice_accuracy', 'style_marker_coverage', 'persona_consistency', \n",
        "                 'clarity', 'overfitting_to_mbti']\n",
        "    corr_data = df[corr_cols].corr()\n",
        "    sns.heatmap(corr_data, annot=True, fmt='.2f', cmap='coolwarm', center=0, \n",
        "                square=True, ax=axes[0, 0])\n",
        "    axes[0, 0].set_title('Correlation Matrix of Evaluation Metrics')\n",
        "    \n",
        "    # 2. Style Marker Coverage vs Voice Accuracy\n",
        "    axes[0, 1].scatter(df['style_marker_coverage'], df['voice_accuracy'], alpha=0.5)\n",
        "    axes[0, 1].set_xlabel('Style Marker Coverage')\n",
        "    axes[0, 1].set_ylabel('Voice Accuracy')\n",
        "    axes[0, 1].set_title('Style Coverage vs Voice Accuracy')\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 3. Persona Consistency vs Voice Accuracy\n",
        "    axes[1, 0].scatter(df['persona_consistency'], df['voice_accuracy'], alpha=0.5)\n",
        "    axes[1, 0].set_xlabel('Persona Consistency')\n",
        "    axes[1, 0].set_ylabel('Voice Accuracy')\n",
        "    axes[1, 0].set_title('Persona Consistency vs Voice Accuracy')\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 4. MBTI Overfitting Distribution\n",
        "    axes[1, 1].hist(df['overfitting_to_mbti'], bins=15, edgecolor='black', alpha=0.7)\n",
        "    axes[1, 1].axvline(df['overfitting_to_mbti'].mean(), color='red', linestyle='--',\n",
        "                       label=f'Mean: {df[\"overfitting_to_mbti\"].mean():.2f}')\n",
        "    axes[1, 1].set_xlabel('MBTI Overfitting Score')\n",
        "    axes[1, 1].set_ylabel('Frequency')\n",
        "    axes[1, 1].set_title('Distribution of MBTI Overfitting Scores')\n",
        "    axes[1, 1].legend()\n",
        "    axes[1, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('metrics_analysis.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"‚úÖ Saved: metrics_analysis.png\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No data to visualize\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if df is not None and len(df) > 0:\n",
        "    # Figure 3: Heatmap of Persona x MBTI Performance\n",
        "    pivot_data = df.pivot_table(\n",
        "        values='voice_accuracy',\n",
        "        index='persona_name',\n",
        "        columns='mbti',\n",
        "        aggfunc='mean'\n",
        "    )\n",
        "    \n",
        "    plt.figure(figsize=(16, 10))\n",
        "    sns.heatmap(pivot_data, annot=True, fmt='.2f', cmap='YlOrRd', \n",
        "                cbar_kws={'label': 'Mean Voice Accuracy'}, linewidths=0.5)\n",
        "    plt.title('Voice Accuracy: Persona √ó MBTI Type Heatmap', fontsize=14, pad=20)\n",
        "    plt.xlabel('MBTI Type', fontsize=12)\n",
        "    plt.ylabel('Persona', fontsize=12)\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('persona_mbti_heatmap.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"‚úÖ Saved: persona_mbti_heatmap.png\")\n",
        "    plt.show()\n",
        "    \n",
        "    # Save pivot table as CSV\n",
        "    pivot_data.to_csv('persona_mbti_heatmap_data.csv')\n",
        "    print(\"‚úÖ Saved: persona_mbti_heatmap_data.csv\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No data to visualize\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Generate Ada Lovelace Essay with Results Analysis\n",
        "\n",
        "Generate the essay incorporating analysis of the experimental results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Download Generated Files\n",
        "\n",
        "Download all generated files including the essay, tables, and visualizations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import json\n",
        "\n",
        "# Setup OpenAI client for OpenRouter\n",
        "def openai_client():\n",
        "    api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
        "    base_url = \"https://openrouter.ai/api/v1\"\n",
        "    \n",
        "    if api_key and api_key.startswith(\"sk-or-v1-\"):\n",
        "        return OpenAI(\n",
        "            api_key=api_key,\n",
        "            base_url=base_url,\n",
        "            default_headers={\n",
        "                \"HTTP-Referer\": \"https://colab.research.google.com\",\n",
        "                \"X-Title\": \"MBTI Faculty Voice Research\"\n",
        "            }\n",
        "        )\n",
        "    return OpenAI(api_key=api_key)\n",
        "\n",
        "client = openai_client()\n",
        "\n",
        "def generate_lovelace_essay(results_summary=None):\n",
        "    \"\"\"Generate essay by Ada Lovelace on MBTI research, incorporating results analysis.\"\"\"\n",
        "    model = os.getenv(\"OPENAI_MODEL\", \"openai/gpt-4o\")\n",
        "    \n",
        "    # Build results context if available\n",
        "    results_context = \"\"\n",
        "    if results_summary:\n",
        "        results_context = f\"\"\"\n",
        "\n",
        "EXPERIMENTAL RESULTS:\n",
        "{results_summary}\n",
        "\n",
        "Please incorporate analysis of these results into your essay, discussing:\n",
        "- What the data reveals about MBTI's effectiveness as a prompt engineering tool\n",
        "- Patterns observed across personae and MBTI types\n",
        "- Implications for the practical utility of MBTI overlays\n",
        "- Limitations and areas for further investigation\n",
        "\"\"\"\n",
        "    \n",
        "    prompt = f\"\"\"You are Ada Lovelace, writing a commonplace essay on the investigation of MBTI's value in prompt engineering for faculty agent accuracy.\n",
        "\n",
        "Context: This research examines whether Myers-Briggs Type Indicator (MBTI) personality overlays improve voice accuracy, consistency, and interpretability in AI faculty agents. The experiment tests 10 faculty personae across 16 MBTI types with 3 test prompts each (480 trials total), using an LLM-as-judge to evaluate voice accuracy.{results_context}\n",
        "\n",
        "Your task: Write a thoughtful, elegant commonplace essay (2000-3000 words) that:\n",
        "- Reflects on the relationship between symbolic systems (like MBTI) and computational mechanisms\n",
        "- Considers how personality frameworks might function as \"prompt compression ontologies\"\n",
        "- Explores the tension between psychological validity and practical utility in AI systems\n",
        "- Discusses the implications for creating coherent, persistent agent identities\n",
        "- If results are provided, analyze the experimental findings and their significance\n",
        "- Maintains your characteristic voice: elegant, analytical, visionary about computation's scope, precise but imaginative, with a \"poetical science\" sensibility\n",
        "- Uses your signature moves: clarify mechanism vs meaning, structured explanation, poetical science sensibility\n",
        "- Avoids modern dev slang, casual tone, or pretending firsthand modern tooling\n",
        "\n",
        "Write in the style of your era (Victorian scientific culture) but addressing contemporary AI systems. Be thoughtful, precise, and allow for the imaginative possibilities while maintaining analytical rigor.\"\"\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"\"\"You are Ada Lovelace, the first computer programmer and a visionary of computation's potential. \n",
        "Your voice is elegant, analytical, visionary about computation's scope, precise but imaginative. \n",
        "You clarify mechanism vs meaning, provide structured explanations, and maintain a 'poetical science' sensibility.\n",
        "You write in the style of Victorian scientific culture, with careful distinctions and elegant prose.\"\"\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "    \n",
        "    print(\"Generating essay by Ada Lovelace...\")\n",
        "    print(f\"Using model: {model}\\n\")\n",
        "    \n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0.8,\n",
        "        max_tokens=4000\n",
        "    )\n",
        "    \n",
        "    essay = response.choices[0].message.content\n",
        "    \n",
        "    # Format as markdown\n",
        "    formatted = f\"\"\"# On the Investigation of MBTI in Prompt Engineering for Faculty Agent Accuracy\n",
        "\n",
        "**Ada Lovelace**\n",
        "\n",
        "*A Commonplace Essay*\n",
        "\n",
        "---\n",
        "\n",
        "{essay}\"\"\"\n",
        "    \n",
        "    print(\"‚úÖ Essay generated!\")\n",
        "    print(f\"\\nPreview (first 500 chars):\\n{essay[:500]}...\")\n",
        "    \n",
        "    return formatted\n",
        "\n",
        "# Generate results summary if data is available\n",
        "results_summary = None\n",
        "if df is not None and len(df) > 0:\n",
        "    results_summary = f\"\"\"\n",
        "Total valid trials: {len(df)}\n",
        "Average voice accuracy: {df['voice_accuracy'].mean():.2f} (range: {df['voice_accuracy'].min():.2f} - {df['voice_accuracy'].max():.2f})\n",
        "Average persona consistency: {df['persona_consistency'].mean():.2f}\n",
        "Average style marker coverage: {df['style_marker_coverage'].mean():.2f}\n",
        "Average MBTI overfitting: {df['overfitting_to_mbti'].mean():.2f}\n",
        "\n",
        "Top 3 MBTI types by voice accuracy:\n",
        "{df.groupby('mbti')['voice_accuracy'].mean().sort_values(ascending=False).head(3).to_string()}\n",
        "\n",
        "Top 3 personae by voice accuracy:\n",
        "{df.groupby('persona_name')['voice_accuracy'].mean().sort_values(ascending=False).head(3).to_string()}\n",
        "\"\"\"\n",
        "\n",
        "# Generate the essay\n",
        "essay_content = generate_lovelace_essay(results_summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Upload to Commonplace\n",
        "\n",
        "Upload the essay to Inquiry Institute Commonplace."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "import re\n",
        "\n",
        "def extract_title_and_content(markdown_text):\n",
        "    \"\"\"Extract title and content from markdown.\"\"\"\n",
        "    lines = markdown_text.split('\\n')\n",
        "    title = None\n",
        "    content_start = 0\n",
        "    \n",
        "    for i, line in enumerate(lines):\n",
        "        if line.startswith('# '):\n",
        "            title = line[2:].strip()\n",
        "            content_start = i + 1\n",
        "            break\n",
        "    \n",
        "    if not title:\n",
        "        title = \"On the Investigation of MBTI in Prompt Engineering for Faculty Agent Accuracy\"\n",
        "    \n",
        "    essay_content = '\\n'.join(lines[content_start:])\n",
        "    essay_content = essay_content.replace('**Ada Lovelace**', '').replace('*A Commonplace Essay*', '').strip()\n",
        "    essay_content = essay_content.lstrip('-').strip()\n",
        "    \n",
        "    return title, essay_content\n",
        "\n",
        "def upload_to_commonplace(title, content, jwt_token=None, use_colab_endpoint=True):\n",
        "    \"\"\"\n",
        "    Upload essay to Commonplace via Supabase Edge Function.\n",
        "    \n",
        "    Uses the colab-commonplace endpoint which supports create/update/get operations.\n",
        "    \"\"\"\n",
        "    \n",
        "    supabase_url = os.getenv(\"NEXT_PUBLIC_SUPABASE_URL\")\n",
        "    supabase_anon_key = os.getenv(\"NEXT_PUBLIC_SUPABASE_ANON_KEY\")\n",
        "    \n",
        "    if not jwt_token:\n",
        "        jwt_token = getpass(\"Enter a.lovelace JWT token (or press Enter to skip upload): \").strip()\n",
        "        if not jwt_token:\n",
        "            print(\"‚ö†Ô∏è  Skipping upload. You can upload manually later.\")\n",
        "            return None\n",
        "    \n",
        "    # Use colab-commonplace endpoint (supports create/update/get)\n",
        "    edge_function_url = f\"{supabase_url}/functions/v1/colab-commonplace\"\n",
        "    \n",
        "    # Convert markdown to HTML (basic conversion)\n",
        "    html_content = content.replace('\\n\\n', '</p><p>').replace('\\n', '<br>')\n",
        "    html_content = f\"<p>{html_content}</p>\"\n",
        "    \n",
        "    payload = {\n",
        "        \"action\": \"create\",\n",
        "        \"entry\": {\n",
        "            \"title\": title,\n",
        "            \"content\": html_content,\n",
        "            \"status\": \"draft\",\n",
        "            \"faculty_slug\": \"a-lovelace\",\n",
        "            \"entry_type\": \"essay\",\n",
        "            \"topics\": [\"mbti\", \"prompt-engineering\", \"faculty-agents\", \"ai-research\"],\n",
        "            \"college\": \"ains\",\n",
        "            \"metadata\": {\n",
        "                \"provenance_mode\": \"ai_generated\",\n",
        "                \"canonical_source_url\": \"https://github.com/InquiryInstitute/Inquiry.Institute/tree/main/mbti-faculty-voice-research\",\n",
        "                \"colab_notebook_url\": \"https://colab.research.google.com/...\",\n",
        "                \"source_refs\": \"Generated by Ada Lovelace faculty agent via Google Colab\",\n",
        "                \"generated_by\": \"Ada Lovelace\",\n",
        "                \"pinned\": False\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {jwt_token}\",\n",
        "        \"apikey\": supabase_anon_key,\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    \n",
        "    print(f\"üì§ Uploading essay to Commonplace...\")\n",
        "    print(f\"   Title: {title}\")\n",
        "    print(f\"   Faculty: a-lovelace\")\n",
        "    print(f\"   Status: draft\")\n",
        "    print(f\"   Endpoint: colab-commonplace\\n\")\n",
        "    \n",
        "    try:\n",
        "        response = requests.post(edge_function_url, headers=headers, json=payload, timeout=30)\n",
        "        \n",
        "        if response.status_code == 201:\n",
        "            result = response.json()\n",
        "            if result.get(\"success\"):\n",
        "                print(\"‚úÖ Essay uploaded successfully!\")\n",
        "                entry = result.get(\"entry\", {})\n",
        "                print(f\"   Entry ID: {entry.get('id')}\")\n",
        "                print(f\"   Permalink: {entry.get('permalink', 'N/A')}\")\n",
        "                print(f\"   Status: {entry.get('status')}\")\n",
        "                print(f\"\\nüí° To update later, use entry ID: {entry.get('id')}\")\n",
        "                return result\n",
        "            else:\n",
        "                print(f\"‚ùå Upload failed: {result.get('error', 'Unknown error')}\")\n",
        "                return None\n",
        "        else:\n",
        "            error_data = response.json() if response.headers.get('content-type', '').startswith('application/json') else response.text\n",
        "            print(f\"‚ùå Upload failed: {response.status_code}\")\n",
        "            print(f\"   Error: {json.dumps(error_data, indent=2)}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Request failed: {e}\")\n",
        "        return None\n",
        "\n",
        "def update_entry(entry_id, jwt_token=None, **updates):\n",
        "    \"\"\"Update an existing Commonplace entry.\"\"\"\n",
        "    supabase_url = os.getenv(\"NEXT_PUBLIC_SUPABASE_URL\")\n",
        "    supabase_anon_key = os.getenv(\"NEXT_PUBLIC_SUPABASE_ANON_KEY\")\n",
        "    \n",
        "    if not jwt_token:\n",
        "        jwt_token = getpass(\"Enter JWT token: \").strip()\n",
        "    \n",
        "    edge_function_url = f\"{supabase_url}/functions/v1/colab-commonplace\"\n",
        "    \n",
        "    payload = {\n",
        "        \"action\": \"update\",\n",
        "        \"entry_id\": entry_id,\n",
        "        \"entry\": updates\n",
        "    }\n",
        "    \n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {jwt_token}\",\n",
        "        \"apikey\": supabase_anon_key,\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    \n",
        "    response = requests.put(edge_function_url, headers=headers, json=payload, timeout=30)\n",
        "    response.raise_for_status()\n",
        "    return response.json()\n",
        "\n",
        "# Extract title and content\n",
        "title, content = extract_title_and_content(essay_content)\n",
        "\n",
        "# Upload (will prompt for JWT token)\n",
        "upload_result = upload_to_commonplace(title, content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# Save essay to file\n",
        "with open('lovelace_essay_mbti_research.md', 'w', encoding='utf-8') as f:\n",
        "    f.write(essay_content)\n",
        "\n",
        "print(\"‚úÖ Essay saved to lovelace_essay_mbti_research.md\")\n",
        "\n",
        "# List all generated files\n",
        "generated_files = [\n",
        "    'lovelace_essay_mbti_research.md',\n",
        "    'voice_accuracy_analysis.png',\n",
        "    'metrics_analysis.png',\n",
        "    'persona_mbti_heatmap.png',\n",
        "    'mbti_summary_table.csv',\n",
        "    'persona_summary_table.csv',\n",
        "    'persona_mbti_heatmap_data.csv'\n",
        "]\n",
        "\n",
        "print(\"\\nüì¶ Generated files:\")\n",
        "for fname in generated_files:\n",
        "    if os.path.exists(fname):\n",
        "        size = os.path.getsize(fname)\n",
        "        print(f\"   ‚úÖ {fname} ({size:,} bytes)\")\n",
        "    else:\n",
        "        print(f\"   ‚ö†Ô∏è  {fname} (not found)\")\n",
        "\n",
        "print(\"\\nüí° To download files, run:\")\n",
        "print(\"   files.download('lovelace_essay_mbti_research.md')\")\n",
        "print(\"   files.download('voice_accuracy_analysis.png')\")\n",
        "print(\"   files.download('metrics_analysis.png')\")\n",
        "print(\"   files.download('persona_mbti_heatmap.png')\")\n",
        "\n",
        "# Uncomment to auto-download all:\n",
        "# for fname in generated_files:\n",
        "#     if os.path.exists(fname):\n",
        "#         files.download(fname)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional: Create a New Research Notebook\n",
        "\n",
        "You can create additional research notebooks using the `create-colab-notebook` edge function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_research_notebook(title, template=\"mbti-research\", research_topic=None, description=None, jwt_token=None):\n",
        "    \"\"\"\n",
        "    Create a new research notebook via Supabase Edge Function.\n",
        "    \n",
        "    Templates:\n",
        "    - mbti-research: Pre-configured for MBTI voice accuracy research\n",
        "    - essay-generation: Template for generating essays in faculty voice\n",
        "    - experiment: General experiment template\n",
        "    - custom: Empty template\n",
        "    \"\"\"\n",
        "    if not jwt_token:\n",
        "        jwt_token = getpass(\"Enter JWT token: \").strip()\n",
        "        if not jwt_token:\n",
        "            print(\"‚ö†Ô∏è  JWT token required to create notebooks\")\n",
        "            return None\n",
        "    \n",
        "    supabase_url = os.getenv(\"NEXT_PUBLIC_SUPABASE_URL\")\n",
        "    supabase_anon_key = os.getenv(\"NEXT_PUBLIC_SUPABASE_ANON_KEY\")\n",
        "    \n",
        "    edge_function_url = f\"{supabase_url}/functions/v1/create-colab-notebook\"\n",
        "    \n",
        "    payload = {\n",
        "        \"title\": title,\n",
        "        \"template\": template,\n",
        "    }\n",
        "    \n",
        "    if research_topic:\n",
        "        payload[\"research_topic\"] = research_topic\n",
        "    if description:\n",
        "        payload[\"description\"] = description\n",
        "    \n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {jwt_token}\",\n",
        "        \"apikey\": supabase_anon_key,\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    \n",
        "    print(f\"üìì Creating research notebook: {title}\")\n",
        "    print(f\"   Template: {template}\\n\")\n",
        "    \n",
        "    try:\n",
        "        response = requests.post(edge_function_url, headers=headers, json=payload, timeout=30)\n",
        "        \n",
        "        if response.status_code == 201:\n",
        "            result = response.json()\n",
        "            if result.get(\"success\"):\n",
        "                print(\"‚úÖ Notebook created!\")\n",
        "                notebook_json = result.get(\"notebook_json\", \"{}\")\n",
        "                \n",
        "                # Save notebook\n",
        "                filename = f\"{title.lower().replace(' ', '_')}.ipynb\"\n",
        "                with open(filename, 'w', encoding='utf-8') as f:\n",
        "                    f.write(notebook_json)\n",
        "                \n",
        "                print(f\"üíæ Saved to: {filename}\")\n",
        "                print(f\"\\nüìù Next steps:\")\n",
        "                print(f\"   1. Download the .ipynb file\")\n",
        "                print(f\"   2. Upload to Google Colab: File ‚Üí Upload notebook\")\n",
        "                print(f\"   3. Or save to GitHub and open from there\")\n",
        "                \n",
        "                return result\n",
        "        else:\n",
        "            error_data = response.json() if response.headers.get('content-type', '').startswith('application/json') else response.text\n",
        "            print(f\"‚ùå Creation failed: {response.status_code}\")\n",
        "            print(f\"   Error: {json.dumps(error_data, indent=2)}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Request failed: {e}\")\n",
        "        return None\n",
        "\n",
        "# Example: Create a new notebook\n",
        "# create_research_notebook(\n",
        "#     title=\"My Research Project\",\n",
        "#     template=\"experiment\",\n",
        "#     research_topic=\"Investigating voice accuracy in AI agents\",\n",
        "#     description=\"A notebook for my research project\"\n",
        "# )"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
