{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MBTI Faculty Voice Research - Google Colab\n",
    "\n",
    "This notebook contains:\n",
    "1. **MBTI Voice Accuracy Experiment** - Run the full 480-trial experiment\n",
    "2. **Ada Lovelace Essay Generation** - Generate essay on MBTI research\n",
    "3. **Upload to Commonplace** - Upload essay to Inquiry Institute Commonplace\n",
    "\n",
    "## Setup\n",
    "\n",
    "1. Install dependencies\n",
    "2. Set API keys (OpenRouter, Supabase)\n",
    "3. Run the cells below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:39:10.662247Z",
     "iopub.status.busy": "2026-01-14T03:39:10.662082Z",
     "iopub.status.idle": "2026-01-14T03:39:12.168753Z",
     "shell.execute_reply": "2026-01-14T03:39:12.168264Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/opt/homebrew/opt/python@3.11/bin/python3.11 -m pip install --upgrade pip\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q openai pydantic python-dotenv requests pandas matplotlib seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure API Keys\n",
    "\n",
    "Set your API keys below. For security, you can use Colab's secrets manager or set them directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:39:12.170569Z",
     "iopub.status.busy": "2026-01-14T03:39:12.170425Z",
     "iopub.status.idle": "2026-01-14T03:39:12.270464Z",
     "shell.execute_reply": "2026-01-14T03:39:12.269988Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  Colab Secrets not available, using manual input...\n",
      "üí° Tip: Set secrets in Colab using the üîë icon in the left sidebar\n",
      "   Secrets to add: OPENROUTER_API_KEY, SUPABASE_URL, SUPABASE_ANON_KEY\n",
      "\n"
     ]
    },
    {
     "ename": "StdinNotImplementedError",
     "evalue": "getpass was called, but this frontend does not support input requests.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m userdata\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müîê Using Colab Secrets Manager...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google.colab'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mStdinNotImplementedError\u001b[39m                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgetpass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m getpass\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# OpenRouter API Key (required for experiment and essay generation)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m OPENROUTER_API_KEY = \u001b[43mgetpass\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEnter OpenRouter API Key (sk-or-v1-...): \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mOPENROUTER_API_KEY\u001b[39m\u001b[33m\"\u001b[39m] = OPENROUTER_API_KEY\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Supabase credentials (required for uploading to Commonplace)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.11/site-packages/ipykernel/kernelbase.py:1256\u001b[39m, in \u001b[36mKernel.getpass\u001b[39m\u001b[34m(self, prompt, stream)\u001b[39m\n\u001b[32m   1254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._allow_stdin:\n\u001b[32m   1255\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mgetpass was called, but this frontend does not support input requests.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[32m   1257\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1258\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n",
      "\u001b[31mStdinNotImplementedError\u001b[39m: getpass was called, but this frontend does not support input requests."
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Try to use Colab Secrets Manager (preferred method)\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    print(\"üîê Using Colab Secrets Manager...\")\n",
    "    \n",
    "    # Get secrets from Colab Secrets Manager\n",
    "    OPENROUTER_API_KEY = userdata.get('OPENROUTER_API_KEY')\n",
    "    SUPABASE_URL = userdata.get('SUPABASE_URL', 'https://xougqdomkoisrxdnagcj.supabase.co')\n",
    "    SUPABASE_ANON_KEY = userdata.get('SUPABASE_ANON_KEY')\n",
    "    \n",
    "    os.environ[\"OPENROUTER_API_KEY\"] = OPENROUTER_API_KEY\n",
    "    os.environ[\"NEXT_PUBLIC_SUPABASE_URL\"] = SUPABASE_URL\n",
    "    os.environ[\"NEXT_PUBLIC_SUPABASE_ANON_KEY\"] = SUPABASE_ANON_KEY\n",
    "    \n",
    "    print(\"‚úÖ API keys loaded from Colab Secrets!\")\n",
    "    \n",
    "except (ModuleNotFoundError, KeyError) as e:\n",
    "    # Fallback to manual input if not in Colab or secrets not set\n",
    "    print(\"‚ö†Ô∏è  Colab Secrets not available, using manual input...\")\n",
    "    print(\"üí° Tip: Set secrets in Colab using the üîë icon in the left sidebar\")\n",
    "    print(\"   Secrets to add: OPENROUTER_API_KEY, SUPABASE_URL, SUPABASE_ANON_KEY\\n\")\n",
    "    \n",
    "    from getpass import getpass\n",
    "    \n",
    "    # OpenRouter API Key (required for experiment and essay generation)\n",
    "    OPENROUTER_API_KEY = getpass(\"Enter OpenRouter API Key (sk-or-v1-...): \")\n",
    "    os.environ[\"OPENROUTER_API_KEY\"] = OPENROUTER_API_KEY\n",
    "    \n",
    "    # Supabase credentials (required for uploading to Commonplace)\n",
    "    SUPABASE_URL = input(\"Enter Supabase URL (https://xxx.supabase.co): \").strip() or \"https://xougqdomkoisrxdnagcj.supabase.co\"\n",
    "    os.environ[\"NEXT_PUBLIC_SUPABASE_URL\"] = SUPABASE_URL\n",
    "    \n",
    "    SUPABASE_ANON_KEY = getpass(\"Enter Supabase Anon Key: \")\n",
    "    os.environ[\"NEXT_PUBLIC_SUPABASE_ANON_KEY\"] = SUPABASE_ANON_KEY\n",
    "    \n",
    "    print(\"\\n‚úÖ API keys configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run MBTI Voice Accuracy Experiment\n",
    "\n",
    "Run the full experiment or load existing results. The experiment tests 10 faculty personae across 16 MBTI types with 3 test prompts each (480 trials total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:39:12.272546Z",
     "iopub.status.busy": "2026-01-14T03:39:12.272372Z",
     "iopub.status.idle": "2026-01-14T03:39:12.625701Z",
     "shell.execute_reply": "2026-01-14T03:39:12.625469Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Running MBTI Voice Accuracy Experiment...\n",
      "   This will test 10 personae √ó 16 MBTI types √ó 3 prompts = 480 trials\n",
      "   This may take 15-30 minutes depending on API response times.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Downloaded mbti_voice_eval.py from GitHub\n",
      "\n",
      "üîÑ Starting experiment execution...\n",
      "\n",
      "‚ùå Error running experiment: 'NoneType' object has no attribute '__dict__'\n",
      "\n",
      "üí° Fallback: You can run it manually with:\n",
      "   !python mbti_voice_eval.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/sg/7k1f9lns75sdtd39z4tnhvjr0000gn/T/ipykernel_51816/3441200319.py\", line 50, in <module>\n",
      "    spec.loader.exec_module(module)\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/Users/danielmcshan/GitHub/mbti-faculty-voice-research/mbti_voice_eval.py\", line 119, in <module>\n",
      "    @dataclass(frozen=True)\n",
      "     ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.13/Frameworks/Python.framework/Versions/3.11/lib/python3.11/dataclasses.py\", line 1222, in wrap\n",
      "    return _process_class(cls, init, repr, eq, order, unsafe_hash,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.13/Frameworks/Python.framework/Versions/3.11/lib/python3.11/dataclasses.py\", line 947, in _process_class\n",
      "    and _is_type(type, cls, dataclasses, dataclasses.KW_ONLY,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.13/Frameworks/Python.framework/Versions/3.11/lib/python3.11/dataclasses.py\", line 712, in _is_type\n",
      "    ns = sys.modules.get(cls.__module__).__dict__\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute '__dict__'\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Load existing results (if available)\n",
    "# Uncomment to skip experiment and use existing results\n",
    "# import pandas as pd\n",
    "# df = pd.read_csv('mbti_voice_results.csv')\n",
    "# df = df[df['voice_accuracy'] != -1]\n",
    "# print(f\"‚úÖ Loaded {len(df)} existing results\")\n",
    "# skip_experiment = True\n",
    "\n",
    "skip_experiment = False  # Set to True to skip running the experiment\n",
    "\n",
    "if not skip_experiment:\n",
    "    print(\"üöÄ Running MBTI Voice Accuracy Experiment...\")\n",
    "    print(\"   This will test 10 personae √ó 16 MBTI types √ó 3 prompts = 480 trials\")\n",
    "    print(\"   This may take 15-30 minutes depending on API response times.\\n\")\n",
    "    \n",
    "    # Upload the experiment script from GitHub or use it directly\n",
    "    # For now, we'll download it from the repo\n",
    "    import requests\n",
    "    \n",
    "    try:\n",
    "        # Download the experiment script from GitHub\n",
    "        script_url = \"https://raw.githubusercontent.com/InquiryInstitute/mbti-faculty-voice-research/main/mbti_voice_eval.py\"\n",
    "        response = requests.get(script_url)\n",
    "        if response.status_code == 200:\n",
    "            with open('mbti_voice_eval.py', 'w') as f:\n",
    "                f.write(response.text)\n",
    "            print(\"‚úÖ Downloaded mbti_voice_eval.py from GitHub\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  Could not download script from GitHub. Please upload mbti_voice_eval.py manually.\")\n",
    "            print(\"   You can upload it via: Files ‚Üí Upload to session storage\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Error downloading script: {e}\")\n",
    "        print(\"   Please upload mbti_voice_eval.py manually via Files ‚Üí Upload\")\n",
    "    \n",
    "    # Now run the experiment\n",
    "    print(\"\\nüîÑ Starting experiment execution...\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Import and run the experiment\n",
    "        import sys\n",
    "        import importlib.util\n",
    "        \n",
    "        if os.path.exists('mbti_voice_eval.py'):\n",
    "            spec = importlib.util.spec_from_file_location(\"mbti_voice_eval\", \"mbti_voice_eval.py\")\n",
    "            if spec is None or spec.loader is None:\n",
    "                raise ImportError(\"Failed to create module spec for mbti_voice_eval.py\")\n",
    "            module = importlib.util.module_from_spec(spec)\n",
    "            # Add the current directory to sys.path for any imports\n",
    "            sys.path.insert(0, os.path.dirname(os.path.abspath('mbti_voice_eval.py')))\n",
    "            spec.loader.exec_module(module)\n",
    "            \n",
    "            # Run the experiment\n",
    "            module.run_experiment()\n",
    "            print(\"\\n‚úÖ Experiment completed! Results saved to mbti_voice_results.csv and mbti_voice_results.jsonl\")\n",
    "        else:\n",
    "            print(\"‚ùå mbti_voice_eval.py not found. Please upload it manually.\")\n",
    "            print(\"   Option 1: Upload via Files ‚Üí Upload to session storage\")\n",
    "            print(\"   Option 2: Run: !wget https://raw.githubusercontent.com/InquiryInstitute/mbti-faculty-voice-research/main/mbti_voice_eval.py\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error running experiment: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        print(\"\\nüí° Fallback: You can run it manually with:\")\n",
    "        print(\"   !python mbti_voice_eval.py\")\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  Skipping experiment - using existing results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze Results and Generate Visualizations\n",
    "\n",
    "Analyze the experiment results and create tables and graphs for inclusion in the essay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:39:12.627778Z",
     "iopub.status.busy": "2026-01-14T03:39:12.627617Z",
     "iopub.status.idle": "2026-01-14T03:39:14.362234Z",
     "shell.execute_reply": "2026-01-14T03:39:14.361866Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 0 valid results from mbti_voice_results.jsonl\n",
      "‚ö†Ô∏è  No results to analyze. Please run the experiment first.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# Set style for better-looking plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "def load_results(jsonl_path=\"mbti_voice_results.jsonl\", csv_path=\"mbti_voice_results.csv\"):\n",
    "    \"\"\"Load experiment results from JSONL or CSV.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Try JSONL first\n",
    "    try:\n",
    "        with open(jsonl_path, 'r') as f:\n",
    "            for line in f:\n",
    "                record = json.loads(line)\n",
    "                if record.get('voice_accuracy') and record.get('voice_accuracy') != -1:\n",
    "                    results.append(record)\n",
    "        print(f\"‚úÖ Loaded {len(results)} valid results from {jsonl_path}\")\n",
    "        return results\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    \n",
    "    # Try CSV\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        # Filter valid results\n",
    "        df_valid = df[df['voice_accuracy'] != -1]\n",
    "        results = df_valid.to_dict('records')\n",
    "        print(f\"‚úÖ Loaded {len(results)} valid results from {csv_path}\")\n",
    "        return results\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ö†Ô∏è  No results file found. Run the experiment first.\")\n",
    "        return []\n",
    "\n",
    "# Load results\n",
    "results = load_results()\n",
    "\n",
    "if results:\n",
    "    df = pd.DataFrame(results)\n",
    "    print(f\"\\nüìä Dataset Summary:\")\n",
    "    print(f\"   Total valid trials: {len(df)}\")\n",
    "    print(f\"   Personae: {df['persona_name'].nunique()}\")\n",
    "    print(f\"   MBTI types: {df['mbti'].nunique()}\")\n",
    "    print(f\"   Average voice accuracy: {df['voice_accuracy'].mean():.2f}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No results to analyze. Please run the experiment first.\")\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:39:14.363725Z",
     "iopub.status.busy": "2026-01-14T03:39:14.363556Z",
     "iopub.status.idle": "2026-01-14T03:39:14.368063Z",
     "shell.execute_reply": "2026-01-14T03:39:14.367700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  No data to summarize\n"
     ]
    }
   ],
   "source": [
    "if df is not None and len(df) > 0:\n",
    "    # Convert numeric columns\n",
    "    numeric_cols = ['voice_accuracy', 'style_marker_coverage', 'persona_consistency', \n",
    "                     'clarity', 'overfitting_to_mbti']\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    # Create summary statistics table\n",
    "    print(\"=\" * 60)\n",
    "    print(\"SUMMARY STATISTICS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    summary_stats = df[numeric_cols].describe()\n",
    "    print(\"\\nOverall Statistics:\")\n",
    "    print(summary_stats.round(2))\n",
    "    \n",
    "    # By MBTI type\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"BY MBTI TYPE\")\n",
    "    print(\"=\" * 60)\n",
    "    mbti_stats = df.groupby('mbti')['voice_accuracy'].agg(['mean', 'std', 'count']).round(2)\n",
    "    mbti_stats.columns = ['Mean Accuracy', 'Std Dev', 'Count']\n",
    "    mbti_stats = mbti_stats.sort_values('Mean Accuracy', ascending=False)\n",
    "    print(mbti_stats)\n",
    "    \n",
    "    # By Persona\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"BY PERSONA\")\n",
    "    print(\"=\" * 60)\n",
    "    persona_stats = df.groupby('persona_name')['voice_accuracy'].agg(['mean', 'std', 'count']).round(2)\n",
    "    persona_stats.columns = ['Mean Accuracy', 'Std Dev', 'Count']\n",
    "    persona_stats = persona_stats.sort_values('Mean Accuracy', ascending=False)\n",
    "    print(persona_stats)\n",
    "    \n",
    "    # Save summary tables\n",
    "    mbti_stats.to_csv('mbti_summary_table.csv')\n",
    "    persona_stats.to_csv('persona_summary_table.csv')\n",
    "    print(\"\\n‚úÖ Summary tables saved to CSV files\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No data to summarize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:39:14.369616Z",
     "iopub.status.busy": "2026-01-14T03:39:14.369517Z",
     "iopub.status.idle": "2026-01-14T03:39:14.375505Z",
     "shell.execute_reply": "2026-01-14T03:39:14.375026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  No data to visualize\n"
     ]
    }
   ],
   "source": [
    "if df is not None and len(df) > 0:\n",
    "    # Figure 1: Voice Accuracy Distribution\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # 1. Histogram of voice accuracy\n",
    "    axes[0, 0].hist(df['voice_accuracy'], bins=20, edgecolor='black', alpha=0.7)\n",
    "    axes[0, 0].axvline(df['voice_accuracy'].mean(), color='red', linestyle='--', \n",
    "                       label=f'Mean: {df[\"voice_accuracy\"].mean():.2f}')\n",
    "    axes[0, 0].set_xlabel('Voice Accuracy Score')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    axes[0, 0].set_title('Distribution of Voice Accuracy Scores')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Voice Accuracy by MBTI Type\n",
    "    mbti_order = df.groupby('mbti')['voice_accuracy'].mean().sort_values(ascending=False).index\n",
    "    mbti_means = df.groupby('mbti')['voice_accuracy'].mean().reindex(mbti_order)\n",
    "    axes[0, 1].barh(range(len(mbti_means)), mbti_means.values)\n",
    "    axes[0, 1].set_yticks(range(len(mbti_means)))\n",
    "    axes[0, 1].set_yticklabels(mbti_means.index)\n",
    "    axes[0, 1].set_xlabel('Mean Voice Accuracy')\n",
    "    axes[0, 1].set_title('Voice Accuracy by MBTI Type')\n",
    "    axes[0, 1].grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # 3. Voice Accuracy by Persona\n",
    "    persona_order = df.groupby('persona_name')['voice_accuracy'].mean().sort_values(ascending=False).index\n",
    "    persona_means = df.groupby('persona_name')['voice_accuracy'].mean().reindex(persona_order)\n",
    "    axes[1, 0].barh(range(len(persona_means)), persona_means.values)\n",
    "    axes[1, 0].set_yticks(range(len(persona_means)))\n",
    "    axes[1, 0].set_yticklabels(persona_means.index, fontsize=8)\n",
    "    axes[1, 0].set_xlabel('Mean Voice Accuracy')\n",
    "    axes[1, 0].set_title('Voice Accuracy by Persona')\n",
    "    axes[1, 0].grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # 4. Box plot: Voice Accuracy by MBTI\n",
    "    df_sorted = df.copy()\n",
    "    df_sorted['mbti'] = pd.Categorical(df_sorted['mbti'], categories=mbti_order)\n",
    "    sns.boxplot(data=df_sorted, y='mbti', x='voice_accuracy', ax=axes[1, 1])\n",
    "    axes[1, 1].set_xlabel('Voice Accuracy Score')\n",
    "    axes[1, 1].set_ylabel('MBTI Type')\n",
    "    axes[1, 1].set_title('Voice Accuracy Distribution by MBTI Type')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('voice_accuracy_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"‚úÖ Saved: voice_accuracy_analysis.png\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No data to visualize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:39:14.377428Z",
     "iopub.status.busy": "2026-01-14T03:39:14.377300Z",
     "iopub.status.idle": "2026-01-14T03:39:14.382193Z",
     "shell.execute_reply": "2026-01-14T03:39:14.381917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  No data to visualize\n"
     ]
    }
   ],
   "source": [
    "if df is not None and len(df) > 0:\n",
    "    # Figure 2: Correlation and Multi-metric Analysis\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # 1. Correlation heatmap\n",
    "    corr_cols = ['voice_accuracy', 'style_marker_coverage', 'persona_consistency', \n",
    "                 'clarity', 'overfitting_to_mbti']\n",
    "    corr_data = df[corr_cols].corr()\n",
    "    sns.heatmap(corr_data, annot=True, fmt='.2f', cmap='coolwarm', center=0, \n",
    "                square=True, ax=axes[0, 0])\n",
    "    axes[0, 0].set_title('Correlation Matrix of Evaluation Metrics')\n",
    "    \n",
    "    # 2. Style Marker Coverage vs Voice Accuracy\n",
    "    axes[0, 1].scatter(df['style_marker_coverage'], df['voice_accuracy'], alpha=0.5)\n",
    "    axes[0, 1].set_xlabel('Style Marker Coverage')\n",
    "    axes[0, 1].set_ylabel('Voice Accuracy')\n",
    "    axes[0, 1].set_title('Style Coverage vs Voice Accuracy')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Persona Consistency vs Voice Accuracy\n",
    "    axes[1, 0].scatter(df['persona_consistency'], df['voice_accuracy'], alpha=0.5)\n",
    "    axes[1, 0].set_xlabel('Persona Consistency')\n",
    "    axes[1, 0].set_ylabel('Voice Accuracy')\n",
    "    axes[1, 0].set_title('Persona Consistency vs Voice Accuracy')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. MBTI Overfitting Distribution\n",
    "    axes[1, 1].hist(df['overfitting_to_mbti'], bins=15, edgecolor='black', alpha=0.7)\n",
    "    axes[1, 1].axvline(df['overfitting_to_mbti'].mean(), color='red', linestyle='--',\n",
    "                       label=f'Mean: {df[\"overfitting_to_mbti\"].mean():.2f}')\n",
    "    axes[1, 1].set_xlabel('MBTI Overfitting Score')\n",
    "    axes[1, 1].set_ylabel('Frequency')\n",
    "    axes[1, 1].set_title('Distribution of MBTI Overfitting Scores')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('metrics_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"‚úÖ Saved: metrics_analysis.png\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No data to visualize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:39:14.383500Z",
     "iopub.status.busy": "2026-01-14T03:39:14.383404Z",
     "iopub.status.idle": "2026-01-14T03:39:14.386347Z",
     "shell.execute_reply": "2026-01-14T03:39:14.386079Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  No data to visualize\n"
     ]
    }
   ],
   "source": [
    "if df is not None and len(df) > 0:\n",
    "    # Figure 3: Heatmap of Persona x MBTI Performance\n",
    "    pivot_data = df.pivot_table(\n",
    "        values='voice_accuracy',\n",
    "        index='persona_name',\n",
    "        columns='mbti',\n",
    "        aggfunc='mean'\n",
    "    )\n",
    "    \n",
    "    plt.figure(figsize=(16, 10))\n",
    "    sns.heatmap(pivot_data, annot=True, fmt='.2f', cmap='YlOrRd', \n",
    "                cbar_kws={'label': 'Mean Voice Accuracy'}, linewidths=0.5)\n",
    "    plt.title('Voice Accuracy: Persona √ó MBTI Type Heatmap', fontsize=14, pad=20)\n",
    "    plt.xlabel('MBTI Type', fontsize=12)\n",
    "    plt.ylabel('Persona', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('persona_mbti_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"‚úÖ Saved: persona_mbti_heatmap.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Save pivot table as CSV\n",
    "    pivot_data.to_csv('persona_mbti_heatmap_data.csv')\n",
    "    print(\"‚úÖ Saved: persona_mbti_heatmap_data.csv\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No data to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate Ada Lovelace Essay with Results Analysis\n",
    "\n",
    "Generate the essay incorporating analysis of the experimental results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Download Generated Files\n",
    "\n",
    "Download all generated files including the essay, tables, and visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:39:14.388152Z",
     "iopub.status.busy": "2026-01-14T03:39:14.388011Z",
     "iopub.status.idle": "2026-01-14T03:39:15.189340Z",
     "shell.execute_reply": "2026-01-14T03:39:15.188979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating essay by Ada Lovelace...\n",
      "Using model: openai/gpt-4o\n",
      "\n"
     ]
    },
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'User not found.', 'code': 401}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAuthenticationError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 111\u001b[39m\n\u001b[32m     96\u001b[39m     results_summary = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[33mTotal valid trials: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m     98\u001b[39m \u001b[33mAverage voice accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[\u001b[33m'\u001b[39m\u001b[33mvoice_accuracy\u001b[39m\u001b[33m'\u001b[39m].mean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (range: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[\u001b[33m'\u001b[39m\u001b[33mvoice_accuracy\u001b[39m\u001b[33m'\u001b[39m].min()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[\u001b[33m'\u001b[39m\u001b[33mvoice_accuracy\u001b[39m\u001b[33m'\u001b[39m].max()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    107\u001b[39m \u001b[38;5;132;01m{\u001b[39;00mdf.groupby(\u001b[33m'\u001b[39m\u001b[33mpersona_name\u001b[39m\u001b[33m'\u001b[39m)[\u001b[33m'\u001b[39m\u001b[33mvoice_accuracy\u001b[39m\u001b[33m'\u001b[39m].mean().sort_values(ascending=\u001b[38;5;28;01mFalse\u001b[39;00m).head(\u001b[32m3\u001b[39m).to_string()\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;66;03m# Generate the essay\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m essay_content = \u001b[43mgenerate_lovelace_essay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults_summary\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 68\u001b[39m, in \u001b[36mgenerate_lovelace_essay\u001b[39m\u001b[34m(results_summary)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mGenerating essay by Ada Lovelace...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     66\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUsing model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4000\u001b[39;49m\n\u001b[32m     73\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m essay = response.choices[\u001b[32m0\u001b[39m].message.content\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# Format as markdown\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.11/site-packages/openai/_utils/_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py:1189\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1142\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1143\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1144\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1186\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m   1187\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1188\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1189\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1191\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1192\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1197\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1198\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1199\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1200\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1201\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1203\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1204\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1205\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1206\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1207\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1208\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1209\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1210\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_retention\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_retention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1211\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1212\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1213\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1214\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1215\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1216\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1217\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1218\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1219\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1220\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1221\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1225\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1226\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1227\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1228\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1229\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1230\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1231\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1232\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1233\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1235\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1236\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1238\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAuthenticationError\u001b[39m: Error code: 401 - {'error': {'message': 'User not found.', 'code': 401}}"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "# Setup OpenAI client for OpenRouter\n",
    "def openai_client():\n",
    "    api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "    base_url = \"https://openrouter.ai/api/v1\"\n",
    "    \n",
    "    if api_key and api_key.startswith(\"sk-or-v1-\"):\n",
    "        return OpenAI(\n",
    "            api_key=api_key,\n",
    "            base_url=base_url,\n",
    "            default_headers={\n",
    "                \"HTTP-Referer\": \"https://colab.research.google.com\",\n",
    "                \"X-Title\": \"MBTI Faculty Voice Research\"\n",
    "            }\n",
    "        )\n",
    "    return OpenAI(api_key=api_key)\n",
    "\n",
    "client = openai_client()\n",
    "\n",
    "def generate_lovelace_essay(results_summary=None):\n",
    "    \"\"\"Generate essay by Ada Lovelace on MBTI research, incorporating results analysis.\"\"\"\n",
    "    model = os.getenv(\"OPENAI_MODEL\", \"openai/gpt-4o\")\n",
    "    \n",
    "    # Build results context if available\n",
    "    results_context = \"\"\n",
    "    if results_summary:\n",
    "        results_context = f\"\"\"\n",
    "\n",
    "EXPERIMENTAL RESULTS:\n",
    "{results_summary}\n",
    "\n",
    "Please incorporate analysis of these results into your essay, discussing:\n",
    "- What the data reveals about MBTI's effectiveness as a prompt engineering tool\n",
    "- Patterns observed across personae and MBTI types\n",
    "- Implications for the practical utility of MBTI overlays\n",
    "- Limitations and areas for further investigation\n",
    "\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"You are Ada Lovelace, writing a commonplace essay on the investigation of MBTI's value in prompt engineering for faculty agent accuracy.\n",
    "\n",
    "Context: This research examines whether Myers-Briggs Type Indicator (MBTI) personality overlays improve voice accuracy, consistency, and interpretability in AI faculty agents. The experiment tests 10 faculty personae across 16 MBTI types with 3 test prompts each (480 trials total), using an LLM-as-judge to evaluate voice accuracy.{results_context}\n",
    "\n",
    "Your task: Write a thoughtful, elegant commonplace essay (2000-3000 words) that:\n",
    "- Reflects on the relationship between symbolic systems (like MBTI) and computational mechanisms\n",
    "- Considers how personality frameworks might function as \"prompt compression ontologies\"\n",
    "- Explores the tension between psychological validity and practical utility in AI systems\n",
    "- Discusses the implications for creating coherent, persistent agent identities\n",
    "- If results are provided, analyze the experimental findings and their significance\n",
    "- Maintains your characteristic voice: elegant, analytical, visionary about computation's scope, precise but imaginative, with a \"poetical science\" sensibility\n",
    "- Uses your signature moves: clarify mechanism vs meaning, structured explanation, poetical science sensibility\n",
    "- Avoids modern dev slang, casual tone, or pretending firsthand modern tooling\n",
    "\n",
    "Write in the style of your era (Victorian scientific culture) but addressing contemporary AI systems. Be thoughtful, precise, and allow for the imaginative possibilities while maintaining analytical rigor.\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"\"\"You are Ada Lovelace, the first computer programmer and a visionary of computation's potential. \n",
    "Your voice is elegant, analytical, visionary about computation's scope, precise but imaginative. \n",
    "You clarify mechanism vs meaning, provide structured explanations, and maintain a 'poetical science' sensibility.\n",
    "You write in the style of Victorian scientific culture, with careful distinctions and elegant prose.\"\"\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    \n",
    "    print(\"Generating essay by Ada Lovelace...\")\n",
    "    print(f\"Using model: {model}\\n\")\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0.8,\n",
    "        max_tokens=4000\n",
    "    )\n",
    "    \n",
    "    essay = response.choices[0].message.content\n",
    "    \n",
    "    # Format as markdown\n",
    "    formatted = f\"\"\"# On the Investigation of MBTI in Prompt Engineering for Faculty Agent Accuracy\n",
    "\n",
    "**Ada Lovelace**\n",
    "\n",
    "*A Commonplace Essay*\n",
    "\n",
    "---\n",
    "\n",
    "{essay}\"\"\"\n",
    "    \n",
    "    print(\"‚úÖ Essay generated!\")\n",
    "    print(f\"\\nPreview (first 500 chars):\\n{essay[:500]}...\")\n",
    "    \n",
    "    return formatted\n",
    "\n",
    "# Generate results summary if data is available\n",
    "results_summary = None\n",
    "if df is not None and len(df) > 0:\n",
    "    results_summary = f\"\"\"\n",
    "Total valid trials: {len(df)}\n",
    "Average voice accuracy: {df['voice_accuracy'].mean():.2f} (range: {df['voice_accuracy'].min():.2f} - {df['voice_accuracy'].max():.2f})\n",
    "Average persona consistency: {df['persona_consistency'].mean():.2f}\n",
    "Average style marker coverage: {df['style_marker_coverage'].mean():.2f}\n",
    "Average MBTI overfitting: {df['overfitting_to_mbti'].mean():.2f}\n",
    "\n",
    "Top 3 MBTI types by voice accuracy:\n",
    "{df.groupby('mbti')['voice_accuracy'].mean().sort_values(ascending=False).head(3).to_string()}\n",
    "\n",
    "Top 3 personae by voice accuracy:\n",
    "{df.groupby('persona_name')['voice_accuracy'].mean().sort_values(ascending=False).head(3).to_string()}\n",
    "\"\"\"\n",
    "\n",
    "# Generate the essay\n",
    "essay_content = generate_lovelace_essay(results_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Upload to Commonplace\n",
    "\n",
    "Upload the essay to Inquiry Institute Commonplace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:39:15.191334Z",
     "iopub.status.busy": "2026-01-14T03:39:15.191179Z",
     "iopub.status.idle": "2026-01-14T03:39:15.226591Z",
     "shell.execute_reply": "2026-01-14T03:39:15.226093Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'essay_content' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 133\u001b[39m\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.json()\n\u001b[32m    132\u001b[39m \u001b[38;5;66;03m# Extract title and content\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m title, content = extract_title_and_content(\u001b[43messay_content\u001b[49m)\n\u001b[32m    135\u001b[39m \u001b[38;5;66;03m# Upload (will prompt for JWT token)\u001b[39;00m\n\u001b[32m    136\u001b[39m upload_result = upload_to_commonplace(title, content)\n",
      "\u001b[31mNameError\u001b[39m: name 'essay_content' is not defined"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "\n",
    "def extract_title_and_content(markdown_text):\n",
    "    \"\"\"Extract title and content from markdown.\"\"\"\n",
    "    lines = markdown_text.split('\\n')\n",
    "    title = None\n",
    "    content_start = 0\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        if line.startswith('# '):\n",
    "            title = line[2:].strip()\n",
    "            content_start = i + 1\n",
    "            break\n",
    "    \n",
    "    if not title:\n",
    "        title = \"On the Investigation of MBTI in Prompt Engineering for Faculty Agent Accuracy\"\n",
    "    \n",
    "    essay_content = '\\n'.join(lines[content_start:])\n",
    "    essay_content = essay_content.replace('**Ada Lovelace**', '').replace('*A Commonplace Essay*', '').strip()\n",
    "    essay_content = essay_content.lstrip('-').strip()\n",
    "    \n",
    "    return title, essay_content\n",
    "\n",
    "def upload_to_commonplace(title, content, jwt_token=None, use_colab_endpoint=True):\n",
    "    \"\"\"\n",
    "    Upload essay to Commonplace via Supabase Edge Function.\n",
    "    \n",
    "    Uses the colab-commonplace endpoint which supports create/update/get operations.\n",
    "    \"\"\"\n",
    "    \n",
    "    supabase_url = os.getenv(\"NEXT_PUBLIC_SUPABASE_URL\")\n",
    "    supabase_anon_key = os.getenv(\"NEXT_PUBLIC_SUPABASE_ANON_KEY\")\n",
    "    \n",
    "    if not jwt_token:\n",
    "        jwt_token = getpass(\"Enter a.lovelace JWT token (or press Enter to skip upload): \").strip()\n",
    "        if not jwt_token:\n",
    "            print(\"‚ö†Ô∏è  Skipping upload. You can upload manually later.\")\n",
    "            return None\n",
    "    \n",
    "    # Use colab-commonplace endpoint (supports create/update/get)\n",
    "    edge_function_url = f\"{supabase_url}/functions/v1/colab-commonplace\"\n",
    "    \n",
    "    # Convert markdown to HTML (basic conversion)\n",
    "    html_content = content.replace('\\n\\n', '</p><p>').replace('\\n', '<br>')\n",
    "    html_content = f\"<p>{html_content}</p>\"\n",
    "    \n",
    "    payload = {\n",
    "        \"action\": \"create\",\n",
    "        \"entry\": {\n",
    "            \"title\": title,\n",
    "            \"content\": html_content,\n",
    "            \"status\": \"draft\",\n",
    "            \"faculty_slug\": \"a-lovelace\",\n",
    "            \"entry_type\": \"essay\",\n",
    "            \"topics\": [\"mbti\", \"prompt-engineering\", \"faculty-agents\", \"ai-research\"],\n",
    "            \"college\": \"ains\",\n",
    "            \"metadata\": {\n",
    "                \"provenance_mode\": \"ai_generated\",\n",
    "                \"canonical_source_url\": \"https://github.com/InquiryInstitute/Inquiry.Institute/tree/main/mbti-faculty-voice-research\",\n",
    "                \"colab_notebook_url\": \"https://colab.research.google.com/...\",\n",
    "                \"source_refs\": \"Generated by Ada Lovelace faculty agent via Google Colab\",\n",
    "                \"generated_by\": \"Ada Lovelace\",\n",
    "                \"pinned\": False\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {jwt_token}\",\n",
    "        \"apikey\": supabase_anon_key,\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    print(f\"üì§ Uploading essay to Commonplace...\")\n",
    "    print(f\"   Title: {title}\")\n",
    "    print(f\"   Faculty: a-lovelace\")\n",
    "    print(f\"   Status: draft\")\n",
    "    print(f\"   Endpoint: colab-commonplace\\n\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(edge_function_url, headers=headers, json=payload, timeout=30)\n",
    "        \n",
    "        if response.status_code == 201:\n",
    "            result = response.json()\n",
    "            if result.get(\"success\"):\n",
    "                print(\"‚úÖ Essay uploaded successfully!\")\n",
    "                entry = result.get(\"entry\", {})\n",
    "                print(f\"   Entry ID: {entry.get('id')}\")\n",
    "                print(f\"   Permalink: {entry.get('permalink', 'N/A')}\")\n",
    "                print(f\"   Status: {entry.get('status')}\")\n",
    "                print(f\"\\nüí° To update later, use entry ID: {entry.get('id')}\")\n",
    "                return result\n",
    "            else:\n",
    "                print(f\"‚ùå Upload failed: {result.get('error', 'Unknown error')}\")\n",
    "                return None\n",
    "        else:\n",
    "            error_data = response.json() if response.headers.get('content-type', '').startswith('application/json') else response.text\n",
    "            print(f\"‚ùå Upload failed: {response.status_code}\")\n",
    "            print(f\"   Error: {json.dumps(error_data, indent=2)}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Request failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def update_entry(entry_id, jwt_token=None, **updates):\n",
    "    \"\"\"Update an existing Commonplace entry.\"\"\"\n",
    "    supabase_url = os.getenv(\"NEXT_PUBLIC_SUPABASE_URL\")\n",
    "    supabase_anon_key = os.getenv(\"NEXT_PUBLIC_SUPABASE_ANON_KEY\")\n",
    "    \n",
    "    if not jwt_token:\n",
    "        jwt_token = getpass(\"Enter JWT token: \").strip()\n",
    "    \n",
    "    edge_function_url = f\"{supabase_url}/functions/v1/colab-commonplace\"\n",
    "    \n",
    "    payload = {\n",
    "        \"action\": \"update\",\n",
    "        \"entry_id\": entry_id,\n",
    "        \"entry\": updates\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {jwt_token}\",\n",
    "        \"apikey\": supabase_anon_key,\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    response = requests.put(edge_function_url, headers=headers, json=payload, timeout=30)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "# Extract title and content\n",
    "title, content = extract_title_and_content(essay_content)\n",
    "\n",
    "# Upload (will prompt for JWT token)\n",
    "upload_result = upload_to_commonplace(title, content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:39:15.229796Z",
     "iopub.status.busy": "2026-01-14T03:39:15.229610Z",
     "iopub.status.idle": "2026-01-14T03:39:15.247975Z",
     "shell.execute_reply": "2026-01-14T03:39:15.247694Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m files\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Save essay to file\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "# Save essay to file\n",
    "with open('lovelace_essay_mbti_research.md', 'w', encoding='utf-8') as f:\n",
    "    f.write(essay_content)\n",
    "\n",
    "print(\"‚úÖ Essay saved to lovelace_essay_mbti_research.md\")\n",
    "\n",
    "# List all generated files\n",
    "generated_files = [\n",
    "    'lovelace_essay_mbti_research.md',\n",
    "    'voice_accuracy_analysis.png',\n",
    "    'metrics_analysis.png',\n",
    "    'persona_mbti_heatmap.png',\n",
    "    'mbti_summary_table.csv',\n",
    "    'persona_summary_table.csv',\n",
    "    'persona_mbti_heatmap_data.csv'\n",
    "]\n",
    "\n",
    "print(\"\\nüì¶ Generated files:\")\n",
    "for fname in generated_files:\n",
    "    if os.path.exists(fname):\n",
    "        size = os.path.getsize(fname)\n",
    "        print(f\"   ‚úÖ {fname} ({size:,} bytes)\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è  {fname} (not found)\")\n",
    "\n",
    "print(\"\\nüí° To download files, run:\")\n",
    "print(\"   files.download('lovelace_essay_mbti_research.md')\")\n",
    "print(\"   files.download('voice_accuracy_analysis.png')\")\n",
    "print(\"   files.download('metrics_analysis.png')\")\n",
    "print(\"   files.download('persona_mbti_heatmap.png')\")\n",
    "\n",
    "# Uncomment to auto-download all:\n",
    "# for fname in generated_files:\n",
    "#     if os.path.exists(fname):\n",
    "#         files.download(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Create a New Research Notebook\n",
    "\n",
    "You can create additional research notebooks using the `create-colab-notebook` edge function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:39:15.249513Z",
     "iopub.status.busy": "2026-01-14T03:39:15.249431Z",
     "iopub.status.idle": "2026-01-14T03:39:15.253788Z",
     "shell.execute_reply": "2026-01-14T03:39:15.253510Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_research_notebook(title, template=\"mbti-research\", research_topic=None, description=None, jwt_token=None):\n",
    "    \"\"\"\n",
    "    Create a new research notebook via Supabase Edge Function.\n",
    "    \n",
    "    Templates:\n",
    "    - mbti-research: Pre-configured for MBTI voice accuracy research\n",
    "    - essay-generation: Template for generating essays in faculty voice\n",
    "    - experiment: General experiment template\n",
    "    - custom: Empty template\n",
    "    \"\"\"\n",
    "    if not jwt_token:\n",
    "        jwt_token = getpass(\"Enter JWT token: \").strip()\n",
    "        if not jwt_token:\n",
    "            print(\"‚ö†Ô∏è  JWT token required to create notebooks\")\n",
    "            return None\n",
    "    \n",
    "    supabase_url = os.getenv(\"NEXT_PUBLIC_SUPABASE_URL\")\n",
    "    supabase_anon_key = os.getenv(\"NEXT_PUBLIC_SUPABASE_ANON_KEY\")\n",
    "    \n",
    "    edge_function_url = f\"{supabase_url}/functions/v1/create-colab-notebook\"\n",
    "    \n",
    "    payload = {\n",
    "        \"title\": title,\n",
    "        \"template\": template,\n",
    "    }\n",
    "    \n",
    "    if research_topic:\n",
    "        payload[\"research_topic\"] = research_topic\n",
    "    if description:\n",
    "        payload[\"description\"] = description\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {jwt_token}\",\n",
    "        \"apikey\": supabase_anon_key,\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    print(f\"üìì Creating research notebook: {title}\")\n",
    "    print(f\"   Template: {template}\\n\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(edge_function_url, headers=headers, json=payload, timeout=30)\n",
    "        \n",
    "        if response.status_code == 201:\n",
    "            result = response.json()\n",
    "            if result.get(\"success\"):\n",
    "                print(\"‚úÖ Notebook created!\")\n",
    "                notebook_json = result.get(\"notebook_json\", \"{}\")\n",
    "                \n",
    "                # Save notebook\n",
    "                filename = f\"{title.lower().replace(' ', '_')}.ipynb\"\n",
    "                with open(filename, 'w', encoding='utf-8') as f:\n",
    "                    f.write(notebook_json)\n",
    "                \n",
    "                print(f\"üíæ Saved to: {filename}\")\n",
    "                print(f\"\\nüìù Next steps:\")\n",
    "                print(f\"   1. Download the .ipynb file\")\n",
    "                print(f\"   2. Upload to Google Colab: File ‚Üí Upload notebook\")\n",
    "                print(f\"   3. Or save to GitHub and open from there\")\n",
    "                \n",
    "                return result\n",
    "        else:\n",
    "            error_data = response.json() if response.headers.get('content-type', '').startswith('application/json') else response.text\n",
    "            print(f\"‚ùå Creation failed: {response.status_code}\")\n",
    "            print(f\"   Error: {json.dumps(error_data, indent=2)}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Request failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example: Create a new notebook\n",
    "# create_research_notebook(\n",
    "#     title=\"My Research Project\",\n",
    "#     template=\"experiment\",\n",
    "#     research_topic=\"Investigating voice accuracy in AI agents\",\n",
    "#     description=\"A notebook for my research project\"\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
